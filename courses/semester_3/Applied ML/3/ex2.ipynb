{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abqbue9K3kKK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8szxTdA2VOM"
      },
      "source": [
        "# Part 3: Transformer based embeddings  \n",
        "\n",
        "## Prequel\n",
        "\n",
        "### Global Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngzD-Ivo2iaY"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "SUBSET_RATIO = 0.01 # We don't have much time and you probably are working on laptops, so I suggest keeping this value. If you want to see results on the full dataset, you can set it to 1.0\n",
        "DEVICE = \"cuda\" # If you don't have a NVIDIA GPU, use \"mps\", \"cpu\" or \"rocm\" depending on your config\n",
        "BATCH_SIZE = 16 # Suggested value for 10GB of VRAM/RAM\n",
        "MODEL_NAME = \"bert-base-uncased\" # You can try out other models if you have time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PN1jfqv3bHr"
      },
      "source": [
        "### Loading IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lsHTf123idw"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "train_dataset = (\n",
        "    dataset[\"train\"]\n",
        "    .shuffle(SEED)\n",
        "    .select(range(int(len(dataset[\"train\"]) * SUBSET_RATIO)))\n",
        ")\n",
        "test_dataset = (\n",
        "    dataset[\"test\"]\n",
        "    .shuffle(SEED)\n",
        "    .select(range(int(len(dataset[\"test\"]) * SUBSET_RATIO)))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJIBDjHY3duf"
      },
      "source": [
        "### Task: Create a function that given embeddings and labels, trains a classifier and returns the predictions on the test set.\n",
        "\n",
        "You should reuse the function of part 1 to compare the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbF-A0_O4FIa"
      },
      "outputs": [],
      "source": [
        "import numpy.typing as npt\n",
        "import numpy as np\n",
        "\n",
        "def fit_predict(train_embeddings, train_labels, test_embeddings) -> npt.NDArray[float]:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a0baJ814SeF"
      },
      "source": [
        "## Experiment 1: Using Pre-trained BERT Embeddings\n",
        "\n",
        "The goal is to use a pretrained language model to generate embeddings for our corpus. We use the LM as is without any additional training (like we did with GloVe in the previous part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO6AOmkk4luG"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        ")\n",
        "\n",
        "tokenizer: PreTrainedTokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7fWWye5F2J"
      },
      "source": [
        "### Task: Create a function that generates BERT embeddings for a given text dataset. You can either use the embedding of the [CLS] token or use any pooling method on the embeddings of all tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMyHcO3C5CyG"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "def embed_documents(model: PreTrainedModel, texts: Iterable[str]) -> npt.NDArray[int]:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gKvkXkD5wy1"
      },
      "source": [
        "### Check that you correctly implemented `embed_documents`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX8BPQf052pR"
      },
      "outputs": [],
      "source": [
        "train_embeddings = embed_documents(model, train_dataset[\"text\"])\n",
        "test_embeddings = embed_documents(model, test_dataset[\"text\"])\n",
        "\n",
        "assert train_embeddings.shape == (len(train_dataset), 768)\n",
        "assert test_embeddings.shape == (len(test_dataset), 768)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maas5nnY6Fz4"
      },
      "source": [
        "### Task: Train a Random Forest classifier on the BERT embeddings and check relevant metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6Ha1GpR6CNH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og-eGw476SXk"
      },
      "source": [
        "### Analysis\n",
        "- How does it compare to previous methods?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSLgYJ7v6vlu"
      },
      "source": [
        "## Experiment 2: Fine-tuning BERT using unsuperivsed MLM objective\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-ZXSbrU6xTc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KReiFG_Y6ys4"
      },
      "source": [
        "### Task: Create a function that tokenizes a batch of texts and use it to tokenize the train and test datasets.\n",
        "\n",
        "You should avoid returning tensors at this stage. This will be handle later with the padding using a data collator.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxM2KWDf64sa"
      },
      "outputs": [],
      "source": [
        "from transformers import BatchEncoding\n",
        "\n",
        "def tokenize_batch(batch) -> BatchEncoding:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnku713F69Oq"
      },
      "outputs": [],
      "source": [
        "# We remove the label column because it confuses the training script\n",
        "tokenized_train_dataset = train_dataset.map(\n",
        "    tokenize_batch, batched=True\n",
        ").remove_columns([\"label\"])\n",
        "tokenized_test_dataset = test_dataset.map(\n",
        "    tokenize_batch, batched=True\n",
        ").remove_columns([\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToGqaky37za6"
      },
      "source": [
        "### Task: Create a data collator that masks the input tokens with a probability of 15%. See [DataCollatorForLanguageModeling](https://huggingface.co/docs/transformers/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp_AeWLJ7mCl"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = None # Fill me!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1O5f1Cu8GVJ"
      },
      "source": [
        "### Task: Train the BERT model with a masked language modeling head on the IMDB dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpAo2ZMa8Gq8"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    BertForMaskedLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "model_mlm = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./mlm_model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    prediction_loss_only=True,\n",
        "    logging_steps=10,\n",
        "    logging_strategy=\"steps\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_mlm,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_test_dataset,\n",
        ")\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqkPWbVC8z6K"
      },
      "source": [
        "### Task: Like before generate BERT embeddings for the train and test datasets using the fine-tuned model and compare the performance of the classifier.\n",
        "Tip: You can access the encoder using `model_mlm.base_model`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crVCDaOr8qw-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ajudzol87AR"
      },
      "source": [
        "### Analysis: Compare the performance of the classifier using the fine-tuned BERT model with the previous experiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2XMfDZi9GCV"
      },
      "source": [
        "## Experiment 3: End-to-End BERT Classification and Embeddings\n",
        "The objective is to finetune the BERT model for sequence classification and use the embeddings from the finetuned model to train a classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUfPBSk9dLU"
      },
      "source": [
        "### Task: Tokenize the train and test datasets using previous function. Split the train dataset into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wis3NcnN9EYP"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(\n",
        "    tokenize_batch, batched=True, remove_columns=[\"text\"]\n",
        ")\n",
        "tokenized_test_dataset = test_dataset.map(\n",
        "    tokenize_batch, batched=True, remove_columns=[\"text\"]\n",
        ")\n",
        "tokenized_train_eval_dataset = tokenized_train_dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "tokenized_train_dataset = tokenized_train_eval_dataset[\"train\"]\n",
        "tokenized_eval_dataset = tokenized_train_eval_dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IQQaRFW9gsj"
      },
      "source": [
        "### Task: Load the BERT model for sequence classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN-8TqUA9blj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "\n",
        "model_classifier = BertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H46V3tZ_9jyH"
      },
      "source": [
        "\n",
        "### Task: Create a data collator that pads the input sequences. Why do we need padding for sequence classification?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El8t46Uz9laJ"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHZW-N992SN"
      },
      "source": [
        "### Task: Create a function that compute relevant metrics for the classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpuw6Yvz9n7H"
      },
      "outputs": [],
      "source": [
        "from transformers import EvalPrediction\n",
        "\n",
        "def compute_metrics(eval_pred: EvalPrediction) -> dict[str, float]:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM5Yf8GV-DYO"
      },
      "source": [
        "### Task: Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLvh-7Bu-Dv_"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./classifier_model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    logging_steps=10,\n",
        "    logging_strategy=\"steps\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    eval_steps=1,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_classifier,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Im94HT-Y_E"
      },
      "source": [
        "### Task: Evaluate the classifier on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGrpvalw-ZX5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI3MQ1zy-he8"
      },
      "source": [
        "### Task: Use the classifier to generate embeddings for the train and test datasets and evaluate the performance of the generic classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKT7hCIp-hzz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8UJv6hy-kpY"
      },
      "source": [
        "### Analysis\n",
        "\n",
        "How does this two last methods compare to the rest?  Can you think of way to improve further what we did?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
