{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e84g1YoseoE"
   },
   "source": [
    "# TextAttack End-to-End\n",
    "\n",
    "This tutorial provides a broad end-to-end overview of training, evaluating, and attacking a model using [TextAttack](https://textattack.readthedocs.io/en/master/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AQTkpf9RslEA",
    "outputId": "c13daaaf-0290-4ac5-f725-06a8ce9a4da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textattack[optional,tensorflow]\n",
      "  Downloading textattack-0.3.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting bert-score>=0.3.5 (from textattack[optional,tensorflow])\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting editdistance (from textattack[optional,tensorflow])\n",
      "  Downloading editdistance-0.8.1-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting flair (from textattack[optional,tensorflow])\n",
      "  Downloading flair-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (3.16.1)\n",
      "Collecting language-tool-python (from textattack[optional,tensorflow])\n",
      "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lemminflect (from textattack[optional,tensorflow])\n",
      "  Downloading lemminflect-0.2.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting lru-dict (from textattack[optional,tensorflow])\n",
      "  Downloading lru_dict-1.3.0-cp39-cp39-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: datasets>=2.4.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (3.0.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (1.10.1)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (2.5.0)\n",
      "Collecting transformers>=4.30.0 (from textattack[optional,tensorflow])\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.1/44.1 kB ? eta 0:00:00\n",
      "Collecting terminaltables (from textattack[optional,tensorflow])\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (4.66.5)\n",
      "Collecting word2number (from textattack[optional,tensorflow])\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting num2words (from textattack[optional,tensorflow])\n",
      "  Downloading num2words-0.5.13-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting more-itertools (from textattack[optional,tensorflow])\n",
      "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting pinyin>=0.4.0 (from textattack[optional,tensorflow])\n",
      "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
      "     ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.8/3.6 MB 17.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.9/3.6 MB 23.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 3.2/3.6 MB 25.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.6/3.6 MB 23.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba (from textattack[optional,tensorflow])\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 1.1/19.2 MB 22.4 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 2.4/19.2 MB 25.9 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 5.7/19.2 MB 28.1 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 7.7/19.2 MB 30.9 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 9.2/19.2 MB 29.3 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 10.5/19.2 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 12.0/19.2 MB 32.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 13.1/19.2 MB 29.8 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 14.7/19.2 MB 32.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 16.4/19.2 MB 32.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 17.4/19.2 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  18.8/19.2 MB 29.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  19.2/19.2 MB 29.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 19.2/19.2 MB 25.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting OpenHowNet (from textattack[optional,tensorflow])\n",
      "  Downloading OpenHowNet-2.0-py3-none-any.whl.metadata (821 bytes)\n",
      "Requirement already satisfied: tensorflow>=2.9.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (2.16.1)\n",
      "Collecting tensorflow-hub (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-text>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_text-2.10.0-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tensorboardX (from textattack[optional,tensorflow])\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting sentence-transformers==2.2.0 (from textattack[optional,tensorflow])\n",
      "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "     ---------------------------------------- 0.0/79.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 79.7/79.7 kB 4.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting stanza (from textattack[optional,tensorflow])\n",
      "  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting visdom (from textattack[optional,tensorflow])\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "     ---------------------------------------  1.4/1.4 MB 45.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.4/1.4 MB 29.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting wandb (from textattack[optional,tensorflow])\n",
      "  Downloading wandb-0.18.7-py3-none-win_amd64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: gensim in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textattack[optional,tensorflow]) (4.3.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (0.20.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (1.2.2)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.0->textattack[optional,tensorflow])\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers==2.2.0->textattack[optional,tensorflow]) (0.26.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score>=0.3.5->textattack[optional,tensorflow]) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score>=0.3.5->textattack[optional,tensorflow]) (3.7.3)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bert-score>=0.3.5->textattack[optional,tensorflow]) (23.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.4.0->textattack[optional,tensorflow]) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (3.8.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets>=2.4.0->textattack[optional,tensorflow]) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.1->textattack[optional,tensorflow]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.1->textattack[optional,tensorflow]) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.1->textattack[optional,tensorflow]) (2023.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (4.25.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.31.0)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.10.1-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting tensorflow-text>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_text-2.9.0-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.9.3-cp39-cp39-win_amd64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorflow-2.9.2-cp39-cp39-win_amd64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorflow-2.9.1-cp39-cp39-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Using cached tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.18.0-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.18.0-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.17.1-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.17.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.17.1-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.17.0-cp39-cp39-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.17.0-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.16.2-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.16.2 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.16.2-cp39-cp39-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Using cached tensorflow-2.16.1-cp39-cp39-win_amd64.whl.metadata (3.5 kB)\n",
      "  Downloading tensorflow-2.15.1-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting tensorflow-intel==2.15.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.15.1-cp39-cp39-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.15.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow-intel==2.15.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow-intel==2.15.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.15.0-cp39-cp39-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting tensorflow-intel==2.15.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.15.0-cp39-cp39-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow-intel==2.15.0->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.14.1-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.14.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.14.1-cp39-cp39-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow-intel==2.14.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.15,>=2.14.0 (from tensorflow-intel==2.14.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.14.0-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.14.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.14.0-cp39-cp39-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.13.1-cp39-cp39-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.13.1-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting numpy>=1.21.0 (from textattack[optional,tensorflow])\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.13.0-cp39-cp39-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.12.1-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting tensorflow-intel==2.12.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.12.1-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.4.24)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting numpy>=1.21.0 (from textattack[optional,tensorflow])\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.11.1-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting tensorflow-intel==2.11.1 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.11.1-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl.metadata (807 bytes)\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.6)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (0.43.0)\n",
      "Collecting tensorflow>=2.9.1 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting tensorflow-intel==2.11.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.11,>=2.10 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-estimator>=2.9.0 (from textattack[optional,tensorflow])\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.11,>=2.10.0 (from tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub->textattack[optional,tensorflow])\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy==1.13.1->torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->textattack[optional,tensorflow]) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers>=4.30.0->textattack[optional,tensorflow]) (2023.3.23)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.30.0->textattack[optional,tensorflow])\n",
      "  Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.30.0->textattack[optional,tensorflow])\n",
      "  Downloading safetensors-0.4.5-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting boto3>=1.20.27 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading boto3-1.35.65-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading Deprecated-1.2.15-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langdetect>=1.0.9 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------------  972.8/981.5 kB 31.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- 981.5/981.5 kB 20.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml>=4.8.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mpld3>=0.3 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting segtok>=1.5.11 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from flair->textattack[optional,tensorflow]) (0.9.0)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting semver<4.0.0,>=3.0.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting bioc<3.0.0,>=2.0.0 (from flair->textattack[optional,tensorflow])\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim->textattack[optional,tensorflow]) (7.0.5)\n",
      "Requirement already satisfied: pip in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from language-tool-python->textattack[optional,tensorflow]) (24.0)\n",
      "Requirement already satisfied: click in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->textattack[optional,tensorflow]) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->textattack[optional,tensorflow]) (1.2.0)\n",
      "Collecting docopt>=0.6.2 (from num2words->textattack[optional,tensorflow])\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting anytree (from OpenHowNet->textattack[optional,tensorflow])\n",
      "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting emoji (from stanza->textattack[optional,tensorflow])\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: tomli in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stanza->textattack[optional,tensorflow]) (2.0.1)\n",
      "INFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboardX (from textattack[optional,tensorflow])\n",
      "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tornado in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from visdom->textattack[optional,tensorflow]) (6.4)\n",
      "Collecting jsonpatch (from visdom->textattack[optional,tensorflow])\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from visdom->textattack[optional,tensorflow]) (1.7.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from visdom->textattack[optional,tensorflow]) (10.0.0)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->textattack[optional,tensorflow])\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->textattack[optional,tensorflow])\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wandb->textattack[optional,tensorflow]) (4.1.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wandb->textattack[optional,tensorflow]) (5.9.6)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->textattack[optional,tensorflow])\n",
      "  Downloading sentry_sdk-2.18.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb->textattack[optional,tensorflow])\n",
      "  Downloading setproctitle-1.3.4-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair->textattack[optional,tensorflow])\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair->textattack[optional,tensorflow])\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting botocore<1.36.0,>=1.35.65 (from boto3>=1.20.27->flair->textattack[optional,tensorflow])\n",
      "  Downloading botocore-1.35.65-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair->textattack[optional,tensorflow])\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.20.27->flair->textattack[optional,tensorflow])\n",
      "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (1.9.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets>=2.4.0->textattack[optional,tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ftfy>=6.1.0->flair->textattack[optional,tensorflow]) (0.2.12)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gdown>=4.4.0->flair->textattack[optional,tensorflow]) (4.12.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->textattack[optional,tensorflow])\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (6.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->bert-score>=0.3.5->textattack[optional,tensorflow]) (2022.12.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.0->textattack[optional,tensorflow]) (3.1.0)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub->textattack[optional,tensorflow])\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack[optional,tensorflow]) (2.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonpatch->visdom->textattack[optional,tensorflow]) (2.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->textattack[optional,tensorflow])\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->bert-score>=0.3.5->textattack[optional,tensorflow]) (3.17.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (7.0.0)\n",
      "Collecting accelerate>=0.26.0 (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack[optional,tensorflow])\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack[optional,tensorflow]) (2.5)\n",
      "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack[optional,tensorflow])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.4.0->flair->textattack[optional,tensorflow])\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow])\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.1->tensorflow>=2.9.1->textattack[optional,tensorflow]) (3.2.2)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.1/61.1 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.10.1-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "   ---------------------------------------- 0.0/455.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/455.9 MB 22.9 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 2.2/455.9 MB 23.1 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 3.6/455.9 MB 29.1 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 5.2/455.9 MB 27.7 MB/s eta 0:00:17\n",
      "    --------------------------------------- 6.3/455.9 MB 26.7 MB/s eta 0:00:17\n",
      "    --------------------------------------- 7.6/455.9 MB 27.0 MB/s eta 0:00:17\n",
      "    --------------------------------------- 9.0/455.9 MB 28.8 MB/s eta 0:00:16\n",
      "    --------------------------------------- 10.5/455.9 MB 28.4 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 12.1/455.9 MB 31.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 13.8/455.9 MB 29.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 15.3/455.9 MB 31.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 17.0/455.9 MB 31.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 18.6/455.9 MB 32.7 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 20.0/455.9 MB 32.7 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 21.5/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 23.2/455.9 MB 29.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 24.8/455.9 MB 32.8 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 26.4/455.9 MB 32.7 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 27.9/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 29.4/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 31.0/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 32.6/455.9 MB 32.8 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 34.2/455.9 MB 32.7 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 35.8/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 37.4/455.9 MB 32.8 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 38.8/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 40.4/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 42.0/455.9 MB 31.1 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 43.7/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 45.2/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 46.9/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 48.4/455.9 MB 31.2 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 49.9/455.9 MB 31.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 51.4/455.9 MB 31.2 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 52.9/455.9 MB 31.2 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 54.4/455.9 MB 29.7 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 56.0/455.9 MB 29.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 57.4/455.9 MB 31.2 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 58.9/455.9 MB 29.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 60.4/455.9 MB 31.2 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 61.8/455.9 MB 31.2 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 63.4/455.9 MB 29.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 64.3/455.9 MB 29.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 65.5/455.9 MB 28.4 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 66.6/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 67.7/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 68.9/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 70.2/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 71.4/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 72.6/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 73.8/455.9 MB 27.3 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 75.2/455.9 MB 28.4 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 76.5/455.9 MB 31.2 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 78.0/455.9 MB 29.8 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 79.5/455.9 MB 29.7 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 81.0/455.9 MB 29.7 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 82.4/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 83.8/455.9 MB 29.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 85.3/455.9 MB 29.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 86.8/455.9 MB 29.7 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 88.2/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 89.8/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 91.2/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 92.6/455.9 MB 28.5 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 94.1/455.9 MB 31.1 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 95.5/455.9 MB 28.5 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 97.0/455.9 MB 29.7 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 98.7/455.9 MB 29.8 MB/s eta 0:00:12\n",
      "   -------- ------------------------------ 100.2/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------ 101.6/455.9 MB 29.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------ 103.2/455.9 MB 29.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------ 104.8/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 106.3/455.9 MB 32.7 MB/s eta 0:00:11\n",
      "   --------- ----------------------------- 107.8/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 109.4/455.9 MB 29.7 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 110.7/455.9 MB 29.7 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 112.4/455.9 MB 31.2 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 114.0/455.9 MB 29.7 MB/s eta 0:00:12\n",
      "   --------- ----------------------------- 115.6/455.9 MB 29.8 MB/s eta 0:00:12\n",
      "   ---------- ---------------------------- 117.2/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 118.9/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 120.3/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 121.9/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 123.2/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 124.9/455.9 MB 32.7 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 126.4/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ---------- ---------------------------- 128.1/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 129.6/455.9 MB 29.8 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 131.2/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 132.9/455.9 MB 31.2 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 134.6/455.9 MB 32.8 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 136.2/455.9 MB 32.7 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 137.9/455.9 MB 32.8 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 139.1/455.9 MB 32.7 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 139.1/455.9 MB 32.7 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 140.1/455.9 MB 26.2 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 141.8/455.9 MB 26.2 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 143.3/455.9 MB 26.2 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 144.7/455.9 MB 25.1 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 146.4/455.9 MB 26.2 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 147.8/455.9 MB 26.2 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 149.4/455.9 MB 32.8 MB/s eta 0:00:10\n",
      "   ------------ -------------------------- 151.0/455.9 MB 34.4 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 152.6/455.9 MB 32.7 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 153.9/455.9 MB 31.1 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 155.3/455.9 MB 31.2 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 156.8/455.9 MB 31.2 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 158.2/455.9 MB 29.7 MB/s eta 0:00:11\n",
      "   ------------- ------------------------- 159.8/455.9 MB 29.7 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 161.1/455.9 MB 29.7 MB/s eta 0:00:10\n",
      "   ------------- ------------------------- 162.5/455.9 MB 29.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 163.7/455.9 MB 29.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 164.8/455.9 MB 27.3 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 166.3/455.9 MB 27.3 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 167.7/455.9 MB 28.5 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 168.9/455.9 MB 29.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 170.2/455.9 MB 28.5 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 171.7/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 173.0/455.9 MB 27.3 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 174.8/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 176.8/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 178.1/455.9 MB 29.7 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 179.7/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 180.8/455.9 MB 27.3 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 182.3/455.9 MB 28.4 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 183.1/455.9 MB 27.3 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 184.3/455.9 MB 27.3 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 185.7/455.9 MB 28.4 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 187.1/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 188.5/455.9 MB 27.3 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 190.0/455.9 MB 27.3 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 191.6/455.9 MB 28.4 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 193.0/455.9 MB 28.4 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 194.3/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 195.8/455.9 MB 28.5 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 197.3/455.9 MB 28.4 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 198.6/455.9 MB 28.4 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 200.0/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 201.2/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 202.6/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 203.9/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 205.2/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 206.6/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 207.9/455.9 MB 28.4 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 208.9/455.9 MB 29.7 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 210.2/455.9 MB 28.4 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 211.6/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 212.6/455.9 MB 27.3 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 214.1/455.9 MB 27.3 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 215.4/455.9 MB 27.3 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 216.9/455.9 MB 28.5 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 218.6/455.9 MB 28.4 MB/s eta 0:00:09\n",
      "   ------------------ -------------------- 220.2/455.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 221.4/455.9 MB 29.7 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 223.0/455.9 MB 31.2 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 224.3/455.9 MB 31.2 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 225.9/455.9 MB 31.2 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 227.6/455.9 MB 32.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 229.2/455.9 MB 32.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 230.8/455.9 MB 32.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 232.4/455.9 MB 31.2 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 233.7/455.9 MB 32.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 235.0/455.9 MB 31.2 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 236.8/455.9 MB 32.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 237.8/455.9 MB 32.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 237.8/455.9 MB 27.3 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 238.8/455.9 MB 25.1 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 240.1/455.9 MB 25.2 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 241.3/455.9 MB 24.2 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 243.0/455.9 MB 24.2 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 244.4/455.9 MB 24.2 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 245.7/455.9 MB 24.2 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 247.1/455.9 MB 25.2 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 248.8/455.9 MB 29.7 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 249.9/455.9 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 251.6/455.9 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 253.1/455.9 MB 31.2 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 254.8/455.9 MB 32.8 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 256.4/455.9 MB 32.8 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 258.1/455.9 MB 32.7 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 259.6/455.9 MB 31.2 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 261.3/455.9 MB 34.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 262.7/455.9 MB 32.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 264.3/455.9 MB 31.2 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 265.7/455.9 MB 31.2 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 266.1/455.9 MB 28.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 267.3/455.9 MB 28.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 268.6/455.9 MB 27.3 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 270.2/455.9 MB 27.3 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 271.9/455.9 MB 27.3 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 273.6/455.9 MB 28.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 275.1/455.9 MB 28.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 276.3/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 277.5/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 278.8/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 280.1/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 281.7/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 283.2/455.9 MB 29.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 284.1/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 286.3/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 287.8/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 289.5/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 290.9/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 292.1/455.9 MB 31.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 293.4/455.9 MB 31.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 295.0/455.9 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 296.1/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 297.5/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 298.9/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 300.4/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 301.8/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 303.0/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 304.3/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 305.6/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 306.8/455.9 MB 29.7 MB/s eta 0:00:06\n",
      "   -------------------------- ------------ 308.1/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 309.6/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 311.1/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 312.9/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 314.5/455.9 MB 32.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 316.0/455.9 MB 34.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 317.3/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 318.7/455.9 MB 31.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 319.9/455.9 MB 29.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 321.5/455.9 MB 32.7 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 323.0/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 324.3/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 325.7/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 327.2/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 328.5/455.9 MB 31.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 329.8/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 331.3/455.9 MB 29.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 332.8/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 334.2/455.9 MB 29.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 335.9/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 337.4/455.9 MB 29.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 338.9/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 340.3/455.9 MB 29.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 341.6/455.9 MB 29.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 343.3/455.9 MB 29.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 344.7/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 346.3/455.9 MB 29.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 347.9/455.9 MB 29.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 349.6/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 350.4/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 351.9/455.9 MB 28.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 353.3/455.9 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 354.8/455.9 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 356.3/455.9 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 357.9/455.9 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 359.3/455.9 MB 28.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 360.9/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 362.3/455.9 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 363.5/455.9 MB 31.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 365.2/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 366.8/455.9 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 368.4/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 370.0/455.9 MB 32.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 371.6/455.9 MB 32.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 373.2/455.9 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 374.9/455.9 MB 32.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 376.4/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 377.6/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 378.9/455.9 MB 32.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 380.6/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 381.7/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 383.6/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 385.2/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 386.6/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 387.8/455.9 MB 29.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 389.8/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 391.2/455.9 MB 29.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 392.8/455.9 MB 31.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 394.4/455.9 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 395.9/455.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 397.5/455.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 399.1/455.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 400.8/455.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 402.4/455.9 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 403.7/455.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 405.4/455.9 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 406.9/455.9 MB 32.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 408.2/455.9 MB 34.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 409.7/455.9 MB 32.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 411.4/455.9 MB 34.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 412.9/455.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 414.3/455.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 415.7/455.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 417.4/455.9 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 419.1/455.9 MB 32.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 419.2/455.9 MB 32.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 419.6/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 420.9/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 422.6/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 424.0/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 425.7/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 427.2/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 428.9/455.9 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 430.4/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 431.8/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 433.1/455.9 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 434.5/455.9 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 436.0/455.9 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 437.1/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 438.7/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 440.4/455.9 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 442.0/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 443.6/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  445.1/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  446.9/455.9 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  448.5/455.9 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  450.2/455.9 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  451.8/455.9 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  453.5/455.9 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.0/455.9 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  455.9/455.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 455.9/455.9 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "   ---------------------------------------- 0.0/438.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 438.7/438.7 kB 26.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_text-2.10.0-cp39-cp39-win_amd64.whl (5.0 MB)\n",
      "   ---------------------------------------- 0.0/5.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.5/5.0 MB 32.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.1/5.0 MB 32.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.8/5.0 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.0/5.0 MB 29.0 MB/s eta 0:00:00\n",
      "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 26.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 28.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 30.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 31.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 29.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 30.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 30.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 26.7 MB/s eta 0:00:00\n",
      "Downloading editdistance-0.8.1-cp39-cp39-win_amd64.whl (79 kB)\n",
      "   ---------------------------------------- 0.0/79.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 79.6/79.6 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading flair-0.14.0-py3-none-any.whl (776 kB)\n",
      "   ---------------------------------------- 0.0/776.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 776.5/776.5 kB 23.9 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
      "Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
      "   ---------------------------------------- 0.0/769.7 kB ? eta -:--:--\n",
      "   --------------------------------------  768.0/769.7 kB 47.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 769.7/769.7 kB 23.7 MB/s eta 0:00:00\n",
      "Downloading lru_dict-1.3.0-cp39-cp39-win_amd64.whl (13 kB)\n",
      "Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 143.3/143.3 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
      "Downloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 33.9 MB/s eta 0:00:00\n",
      "Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "   ---------------------------------------- 0.0/114.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 114.5/114.5 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Downloading textattack-0.3.10-py3-none-any.whl (445 kB)\n",
      "   ---------------------------------------- 0.0/445.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 445.7/445.7 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading wandb-0.18.7-py3-none-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/15.5 MB 51.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/15.5 MB 33.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.5 MB 30.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/15.5 MB 31.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.0/15.5 MB 32.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.7/15.5 MB 32.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.4/15.5 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.0/15.5 MB 32.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.7/15.5 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 28.5 MB/s eta 0:00:00\n",
      "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading boto3-1.35.65-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.8/44.8 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/207.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 207.3/207.3 kB 12.3 MB/s eta 0:00:00\n",
      "Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.7/1.7 MB 53.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 35.6 MB/s eta 0:00:00\n",
      "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.5/3.8 MB 31.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 39.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 26.9 MB/s eta 0:00:00\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "   ---------------------------------------- 0.0/202.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 202.6/202.6 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "   ---------------------------------------- 0.0/895.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 895.9/895.9 kB 27.7 MB/s eta 0:00:00\n",
      "Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.1/286.1 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading sentry_sdk-2.18.0-py2.py3-none-any.whl (317 kB)\n",
      "   ---------------------------------------- 0.0/317.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 317.5/317.5 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "   ---------------------------------------- 0.0/5.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.5/5.9 MB 46.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.1/5.9 MB 39.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.7/5.9 MB 37.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.9/5.9 MB 34.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.9/5.9 MB 26.8 MB/s eta 0:00:00\n",
      "Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.5/1.7 MB 46.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 21.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.3-cp39-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.6/2.4 MB 52.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 25.5 MB/s eta 0:00:00\n",
      "Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 30.7 MB/s eta 0:00:00\n",
      "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "   ---------------------------------------- 0.0/586.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 586.9/586.9 kB 18.6 MB/s eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading setproctitle-1.3.4-cp39-cp39-win_amd64.whl (12 kB)\n",
      "Downloading botocore-1.35.65-py3-none-any.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.7/12.9 MB 52.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.3/12.9 MB 41.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.9/12.9 MB 34.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.6/12.9 MB 35.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.3/12.9 MB 35.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.9 MB 33.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 209.5/209.5 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.6/82.6 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "   ---------------------------------------- 0.0/781.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 781.3/781.3 kB 24.9 MB/s eta 0:00:00\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "   ---------------------------------------- 0.0/333.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 333.2/333.2 kB 20.2 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 181.5/181.5 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "   ---------------------------------------- 0.0/83.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 83.1/83.1 kB 4.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sentence-transformers, pinyin, jieba, visdom, word2number, docopt, langdetect, pptree, sqlitedict, wikipedia-api, intervaltree\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120781 sha256=e6434ad691d8bcef2947df70d7045c46af0cd6de067b5141802e56213ad16bfe\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\2b\\11\\3b\\32a18fb9f2253b25d3d1a06f0a84e2d516e7efa19c8c71a283\n",
      "  Building wheel for pinyin (setup.py): started\n",
      "  Building wheel for pinyin (setup.py): finished with status 'done'\n",
      "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630514 sha256=ce7e1836f50f50548c782db7f46815d3293c5605aba788d5b6d070c632b4d61c\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\91\\4d\\03\\beb69f9530864b62f295333257151b845f5f871b9a32665b9e\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314494 sha256=910e8ddb240cb356cdd3ffcf3483ada2a0c33e346c3ea57d592bf53738cb0e40\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\7d\\74\\cf\\08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
      "  Building wheel for visdom (setup.py): started\n",
      "  Building wheel for visdom (setup.py): finished with status 'done'\n",
      "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408331 sha256=cb46be92802684949465455c23cf958ee08703b44eaf9d633507f30ba3915124\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\58\\9e\\14\\30f7cc4dafdd4d602fb00ca33c6edd1424fc0f5df10a02e060\n",
      "  Building wheel for word2number (setup.py): started\n",
      "  Building wheel for word2number (setup.py): finished with status 'done'\n",
      "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5600 sha256=637a875cdfcd23cd9abbe21c95a21056505ff514fb30a470f69176462f9579a9\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\a0\\4a\\5b\\d2f2df5c344ddbecb8bea759872c207ea91d93f57fb54e816e\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13792 sha256=aed3ec0aeb3bb657b93bda7fc70e6a9f3730735fd01c6e9cf65f077c4fff5cf9\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993274 sha256=e920869121c3d0ae26be30f5964aa2a9754b9bdd4df4d1c47e9bc3a171d3d125\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "  Building wheel for pptree (setup.py): started\n",
      "  Building wheel for pptree (setup.py): finished with status 'done'\n",
      "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4636 sha256=3d7c28843a9c946248cae11a9f8e23e3d733c58e24a25d022cfc75e331ad8a0a\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\52\\0e\\51\\514e690004ea9713bc3fdb678d5e2768fcc597d0c3b6a3abd2\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16904 sha256=104d4f23db011032c3d6bac6c1af8251c9c38d0892eb2114146b74b9b059fcc5\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\f6\\48\\c4\\942f7a1d556fddd2348cb9ac262f251873dfd8a39afec5678e\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14401 sha256=a0da0c89b9f827a345df1880915dd6e887de1cf5549b9e120ca74ec4bf5c3108\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\3c\\27\\86\\6352987e263844a6793aef9a0485e9ebbf8b93cd1f9b020563\n",
      "  Building wheel for intervaltree (setup.py): started\n",
      "  Building wheel for intervaltree (setup.py): finished with status 'done'\n",
      "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26143 sha256=8e497c3c592a50fcf5f76ee692978fdeaa6f2f237d418cd4df06f11f6f8de924\n",
      "  Stored in directory: c:\\users\\ant\\appdata\\local\\pip\\cache\\wheels\\ab\\fa\\1b\\75d9a713279796785711bd0bad8334aaace560c0bd28830c8c\n",
      "Successfully built sentence-transformers pinyin jieba visdom word2number docopt langdetect pptree sqlitedict wikipedia-api intervaltree\n",
      "Installing collected packages: word2number, tensorboard-plugin-wit, sqlitedict, sortedcontainers, sentencepiece, pptree, pinyin, keras, jieba, docopt, tf-keras, terminaltables, tensorflow-estimator, tensorboard-data-server, smmap, setproctitle, sentry-sdk, semver, segtok, safetensors, PySocks, pyasn1, protobuf, num2words, more-itertools, lxml, lru-dict, lemminflect, langdetect, keras-preprocessing, jsonpatch, jsonlines, jmespath, intervaltree, gast, ftfy, emoji, editdistance, docker-pycreds, deprecated, conllu, cachetools, anytree, wikipedia-api, visdom, tensorflow-hub, tensorboardX, rsa, pyasn1-modules, OpenHowNet, language-tool-python, gitdb, botocore, bioc, tokenizers, stanza, s3transfer, pytorch-revgrad, mpld3, google-auth, gitpython, gdown, accelerate, wandb, transformers, google-auth-oauthlib, boto3, tensorboard, sentence-transformers, bert-score, transformer-smaller-training-vocab, tensorflow, tensorflow-text, flair, textattack\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.2.0\n",
      "    Uninstalling keras-3.2.0:\n",
      "      Successfully uninstalled keras-3.2.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.4\n",
      "    Uninstalling gast-0.5.4:\n",
      "      Successfully uninstalled gast-0.5.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "Successfully installed OpenHowNet-2.0 PySocks-1.7.1 accelerate-1.1.1 anytree-2.12.1 bert-score-0.3.13 bioc-2.1 boto3-1.35.65 botocore-1.35.65 cachetools-5.5.0 conllu-4.5.3 deprecated-1.2.15 docker-pycreds-0.4.0 docopt-0.6.2 editdistance-0.8.1 emoji-2.14.0 flair-0.14.0 ftfy-6.3.1 gast-0.4.0 gdown-5.2.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.36.0 google-auth-oauthlib-0.4.6 intervaltree-3.1.0 jieba-0.42.1 jmespath-1.0.1 jsonlines-4.0.0 jsonpatch-1.33 keras-2.10.0 keras-preprocessing-1.1.2 langdetect-1.0.9 language-tool-python-2.8.1 lemminflect-0.2.3 lru-dict-1.3.0 lxml-5.3.0 more-itertools-10.5.0 mpld3-0.5.10 num2words-0.5.13 pinyin-0.4.0 pptree-3.1 protobuf-3.19.6 pyasn1-0.6.1 pyasn1-modules-0.4.1 pytorch-revgrad-0.2.0 rsa-4.9 s3transfer-0.10.3 safetensors-0.4.5 segtok-1.5.11 semver-3.0.2 sentence-transformers-2.2.0 sentencepiece-0.2.0 sentry-sdk-2.18.0 setproctitle-1.3.4 smmap-5.0.1 sortedcontainers-2.4.0 sqlitedict-2.1.0 stanza-1.9.2 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.6 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tensorflow-hub-0.16.1 tensorflow-text-2.10.0 terminaltables-3.1.10 textattack-0.3.10 tf-keras-2.15.0 tokenizers-0.20.3 transformer-smaller-training-vocab-0.4.0 transformers-4.46.3 visdom-0.2.4 wandb-0.18.7 wikipedia-api-0.7.1 word2number-1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.16.1 requires keras>=3.0.0, but you have keras 2.10.0 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires tensorboard<2.17,>=2.16, but you have tensorboard 2.10.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install textattack[tensorflow,optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bRU0ibw3etFs",
    "outputId": "6e69c847-85cb-4ae4-f82f-cad353f2d42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.12\n",
      "  Using cached tensorflow-2.12.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting tensorflow-intel==2.12.0 (from tensorflow==2.12)\n",
      "  Using cached tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.11.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.24)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (18.1.1)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading protobuf-4.25.5-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (4.12.2)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.62.1)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12) (0.43.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (7.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.36.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.32.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ant\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.2.2)\n",
      "Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "   ---------------------------------------- 0.0/272.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/272.8 MB 32.6 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 1.3/272.8 MB 16.1 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 2.1/272.8 MB 15.0 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 3.3/272.8 MB 17.5 MB/s eta 0:00:16\n",
      "    --------------------------------------- 4.2/272.8 MB 18.1 MB/s eta 0:00:15\n",
      "    --------------------------------------- 5.6/272.8 MB 19.0 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 6.9/272.8 MB 20.1 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 7.9/272.8 MB 21.1 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 9.4/272.8 MB 22.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 10.6/272.8 MB 22.6 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 12.5/272.8 MB 27.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 13.4/272.8 MB 26.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 14.5/272.8 MB 27.3 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 16.0/272.8 MB 27.3 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 17.7/272.8 MB 28.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 19.1/272.8 MB 28.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 20.2/272.8 MB 28.4 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 21.7/272.8 MB 28.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 23.1/272.8 MB 28.5 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 24.3/272.8 MB 31.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 25.7/272.8 MB 31.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 27.2/272.8 MB 31.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 28.4/272.8 MB 29.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 30.1/272.8 MB 29.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 31.1/272.8 MB 29.7 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 32.2/272.8 MB 28.4 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 33.4/272.8 MB 26.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 34.5/272.8 MB 26.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 35.5/272.8 MB 25.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 36.5/272.8 MB 24.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 37.7/272.8 MB 25.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 38.7/272.8 MB 24.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 40.0/272.8 MB 22.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 41.2/272.8 MB 22.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 42.3/272.8 MB 23.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 43.5/272.8 MB 24.2 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 44.0/272.8 MB 23.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 44.6/272.8 MB 21.8 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 45.8/272.8 MB 21.8 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 46.9/272.8 MB 21.1 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 48.0/272.8 MB 21.8 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 48.9/272.8 MB 21.8 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 49.6/272.8 MB 19.8 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 50.7/272.8 MB 20.5 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 51.6/272.8 MB 19.3 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 52.6/272.8 MB 19.3 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 53.5/272.8 MB 18.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 54.6/272.8 MB 20.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 55.7/272.8 MB 20.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 56.8/272.8 MB 20.5 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 58.1/272.8 MB 19.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 58.9/272.8 MB 19.8 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 60.1/272.8 MB 22.6 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 61.3/272.8 MB 21.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 62.2/272.8 MB 21.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 63.1/272.8 MB 21.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 64.0/272.8 MB 22.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 64.8/272.8 MB 21.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 65.6/272.8 MB 21.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 66.5/272.8 MB 20.5 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 67.4/272.8 MB 21.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 68.7/272.8 MB 20.5 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 69.7/272.8 MB 20.5 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 70.8/272.8 MB 20.5 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 71.8/272.8 MB 19.8 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 72.8/272.8 MB 19.3 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 73.8/272.8 MB 20.5 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 74.8/272.8 MB 20.5 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 75.8/272.8 MB 21.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 77.3/272.8 MB 21.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 78.3/272.8 MB 21.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 79.4/272.8 MB 21.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 80.4/272.8 MB 21.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 81.4/272.8 MB 21.8 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 82.5/272.8 MB 21.9 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 83.4/272.8 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 84.6/272.8 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 85.6/272.8 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 86.9/272.8 MB 22.5 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 88.0/272.8 MB 21.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 89.0/272.8 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 89.7/272.8 MB 22.6 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 90.8/272.8 MB 21.8 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 91.7/272.8 MB 21.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 92.2/272.8 MB 19.8 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 93.2/272.8 MB 20.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 94.1/272.8 MB 20.5 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 94.9/272.8 MB 19.8 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 95.9/272.8 MB 19.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 97.1/272.8 MB 19.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 98.2/272.8 MB 19.3 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 99.6/272.8 MB 19.8 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 100.8/272.8 MB 22.6 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 101.9/272.8 MB 21.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------ 103.0/272.8 MB 22.5 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 103.8/272.8 MB 22.6 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 104.8/272.8 MB 24.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 105.9/272.8 MB 24.2 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 106.8/272.8 MB 23.4 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 107.7/272.8 MB 22.6 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 108.8/272.8 MB 21.8 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 109.9/272.8 MB 21.9 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 111.0/272.8 MB 20.5 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 112.2/272.8 MB 21.8 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 113.4/272.8 MB 21.8 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 114.4/272.8 MB 21.1 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 115.3/272.8 MB 21.1 MB/s eta 0:00:08\n",
      "   ---------------- ---------------------- 116.4/272.8 MB 22.6 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 117.4/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 118.6/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 119.8/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 121.1/272.8 MB 24.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 122.1/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 123.0/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 124.1/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 125.2/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 126.5/272.8 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 127.8/272.8 MB 24.2 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 128.4/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 129.8/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 130.6/272.8 MB 22.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 131.5/272.8 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 132.6/272.8 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 133.6/272.8 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 134.6/272.8 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 135.7/272.8 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 136.8/272.8 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 137.9/272.8 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 139.3/272.8 MB 21.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 140.9/272.8 MB 23.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 142.4/272.8 MB 24.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 144.0/272.8 MB 25.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 145.6/272.8 MB 28.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 146.5/272.8 MB 28.4 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 146.5/272.8 MB 28.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 147.0/272.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 147.7/272.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 149.2/272.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 150.3/272.8 MB 24.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 151.6/272.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 153.1/272.8 MB 23.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 154.2/272.8 MB 22.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 155.2/272.8 MB 21.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 155.9/272.8 MB 21.1 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 157.5/272.8 MB 28.4 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 158.5/272.8 MB 27.3 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 159.9/272.8 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 161.5/272.8 MB 28.4 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 163.0/272.8 MB 27.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 164.4/272.8 MB 28.5 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 165.7/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 166.7/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 168.4/272.8 MB 28.4 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 169.8/272.8 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 171.3/272.8 MB 29.8 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 172.5/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 174.2/272.8 MB 31.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 175.8/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 176.4/272.8 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 177.6/272.8 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 179.1/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 180.8/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 182.2/272.8 MB 29.7 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 183.3/272.8 MB 28.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 184.4/272.8 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 186.0/272.8 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 187.5/272.8 MB 31.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 188.6/272.8 MB 29.8 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 189.7/272.8 MB 28.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 190.8/272.8 MB 27.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 191.6/272.8 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 192.7/272.8 MB 25.1 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 193.7/272.8 MB 24.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 194.7/272.8 MB 23.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 195.8/272.8 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 197.5/272.8 MB 21.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 198.9/272.8 MB 23.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 200.5/272.8 MB 24.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 202.3/272.8 MB 26.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 203.7/272.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 205.4/272.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 207.0/272.8 MB 32.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 208.4/272.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 209.7/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 211.4/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 213.0/272.8 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 214.6/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 216.3/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 217.8/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 219.2/272.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 220.9/272.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 222.6/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 224.2/272.8 MB 32.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 225.6/272.8 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 226.8/272.8 MB 31.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 228.0/272.8 MB 29.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 229.4/272.8 MB 29.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 230.9/272.8 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 232.4/272.8 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 234.1/272.8 MB 28.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 235.6/272.8 MB 28.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 236.8/272.8 MB 28.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 238.5/272.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 240.0/272.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 241.4/272.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 242.8/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 244.4/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 246.0/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 247.7/272.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 249.1/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 250.6/272.8 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 252.0/272.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 253.4/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 255.1/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 256.0/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 256.7/272.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 259.2/272.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 260.7/272.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 262.5/272.8 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 264.0/272.8 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 265.4/272.8 MB 31.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  267.1/272.8 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  268.4/272.8 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  269.5/272.8 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  271.2/272.8 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.8/272.8 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 272.8/272.8 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 22.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 18.6 MB/s eta 0:00:00\n",
      "Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "   ---------------------------------------- 0.0/14.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.2/14.7 MB 26.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.8/14.7 MB 30.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.1/14.7 MB 33.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.5/14.7 MB 32.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.0/14.7 MB 32.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.6/14.7 MB 32.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.1/14.7 MB 32.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.4/14.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.5/14.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.9/14.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/14.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.7/14.7 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.5-cp39-cp39-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 413.4/413.4 kB 13.0 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.1/5.6 MB 36.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.0/5.6 MB 32.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.0/5.6 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.7/5.6 MB 25.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 23.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 24.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 22.5 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 440.7/440.7 kB 13.9 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: wrapt, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, keras, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.10.0\n",
      "    Uninstalling tensorflow-estimator-2.10.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.10.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.10.0\n",
      "    Uninstalling keras-2.10.0:\n",
      "      Successfully uninstalled keras-2.10.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.1\n",
      "    Uninstalling tensorboard-2.10.1:\n",
      "      Successfully uninstalled tensorboard-2.10.1\n",
      "  Attempting uninstall: tensorflow-intel\n",
      "    Found existing installation: tensorflow-intel 2.16.1\n",
      "    Uninstalling tensorflow-intel-2.16.1:\n",
      "      Successfully uninstalled tensorflow-intel-2.16.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.10.1\n",
      "    Uninstalling tensorflow-2.10.1:\n",
      "      Successfully uninstalled tensorflow-2.10.1\n",
      "Successfully installed google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 protobuf-4.25.5 tensorboard-2.12.3 tensorboard-data-server-0.7.2 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chex 0.1.85 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 4.25.5 which is incompatible.\n",
      "tensorflow-text 2.10.0 requires tensorflow<2.11,>=2.10.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.12.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONayD5EJseoG"
   },
   "source": [
    "## Training\n",
    "Text attack comes with its own fine tuned models on several datasets. You can list them with the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thVtyRTkGeFu",
    "outputId": "6ce6d772-02db-4698-b1cf-dd3ac379e2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94malbert-base-v2\u001b[0m\n",
      "\u001b[94malbert-base-v2-ag-news\u001b[0m\n",
      "\u001b[94malbert-base-v2-cola\u001b[0m\n",
      "\u001b[94malbert-base-v2-imdb\u001b[0m\n",
      "\u001b[94malbert-base-v2-mr\u001b[0m\n",
      "\u001b[94malbert-base-v2-qqp\u001b[0m\n",
      "\u001b[94malbert-base-v2-rte\u001b[0m\n",
      "\u001b[94malbert-base-v2-snli\u001b[0m\n",
      "\u001b[94malbert-base-v2-sst2\u001b[0m\n",
      "\u001b[94malbert-base-v2-stsb\u001b[0m\n",
      "\u001b[94malbert-base-v2-wnli\u001b[0m\n",
      "\u001b[94malbert-base-v2-yelp\u001b[0m\n",
      "\u001b[94mbert-base-uncased\u001b[0m\n",
      "\u001b[94mbert-base-uncased-ag-news\u001b[0m\n",
      "\u001b[94mbert-base-uncased-cola\u001b[0m\n",
      "\u001b[94mbert-base-uncased-imdb\u001b[0m\n",
      "\u001b[94mbert-base-uncased-mnli\u001b[0m\n",
      "\u001b[94mbert-base-uncased-mr\u001b[0m\n",
      "\u001b[94mbert-base-uncased-mrpc\u001b[0m\n",
      "\u001b[94mbert-base-uncased-qnli\u001b[0m\n",
      "\u001b[94mbert-base-uncased-qqp\u001b[0m\n",
      "\u001b[94mbert-base-uncased-rte\u001b[0m\n",
      "\u001b[94mbert-base-uncased-snli\u001b[0m\n",
      "\u001b[94mbert-base-uncased-sst2\u001b[0m\n",
      "\u001b[94mbert-base-uncased-stsb\u001b[0m\n",
      "\u001b[94mbert-base-uncased-wnli\u001b[0m\n",
      "\u001b[94mbert-base-uncased-yelp\u001b[0m\n",
      "\u001b[94mcnn-ag-news\u001b[0m\n",
      "\u001b[94mcnn-imdb\u001b[0m\n",
      "\u001b[94mcnn-mr\u001b[0m\n",
      "\u001b[94mcnn-sst2\u001b[0m\n",
      "\u001b[94mcnn-yelp\u001b[0m\n",
      "\u001b[94mdistilbert-base-cased-cola\u001b[0m\n",
      "\u001b[94mdistilbert-base-cased-mrpc\u001b[0m\n",
      "\u001b[94mdistilbert-base-cased-qqp\u001b[0m\n",
      "\u001b[94mdistilbert-base-cased-snli\u001b[0m\n",
      "\u001b[94mdistilbert-base-cased-sst2\u001b[0m\n",
      "\u001b[94mdistilbert-base-cased-stsb\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-ag-news\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-cola\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-imdb\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-mnli\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-mr\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-mrpc\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-qnli\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-rte\u001b[0m\n",
      "\u001b[94mdistilbert-base-uncased-wnli\u001b[0m\n",
      "\u001b[94mlstm-ag-news\u001b[0m\n",
      "\u001b[94mlstm-imdb\u001b[0m\n",
      "\u001b[94mlstm-mr\u001b[0m\n",
      "\u001b[94mlstm-sst2\u001b[0m\n",
      "\u001b[94mlstm-yelp\u001b[0m\n",
      "\u001b[94mroberta-base\u001b[0m\n",
      "\u001b[94mroberta-base-ag-news\u001b[0m\n",
      "\u001b[94mroberta-base-cola\u001b[0m\n",
      "\u001b[94mroberta-base-imdb\u001b[0m\n",
      "\u001b[94mroberta-base-mr\u001b[0m\n",
      "\u001b[94mroberta-base-mrpc\u001b[0m\n",
      "\u001b[94mroberta-base-qnli\u001b[0m\n",
      "\u001b[94mroberta-base-rte\u001b[0m\n",
      "\u001b[94mroberta-base-sst2\u001b[0m\n",
      "\u001b[94mroberta-base-stsb\u001b[0m\n",
      "\u001b[94mroberta-base-wnli\u001b[0m\n",
      "\u001b[94mt5-en-de\u001b[0m\n",
      "\u001b[94mt5-en-fr\u001b[0m\n",
      "\u001b[94mt5-en-ro\u001b[0m\n",
      "\u001b[94mt5-summarization\u001b[0m\n",
      "\u001b[94mxlnet-base-cased\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-cola\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-imdb\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-mr\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-mrpc\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-rte\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-stsb\u001b[0m\n",
      "\u001b[94mxlnet-base-cased-wnli\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Updating TextAttack package dependencies.\n",
      "textattack: Downloading NLTK required packages.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\Ant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Ant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|          | 0.00/48.5k [00:00<?, ?B/s]\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 156MB/s]                     \n",
      "2024-11-20 15:30:47 INFO: Downloaded file to C:\\Users\\Ant\\stanza_resources\\resources.json\n",
      "2024-11-20 15:30:47 INFO: Downloading default packages for language: en (English) ...\n",
      "\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   0%|          | 0.00/526M [00:00<?, ?B/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   0%|          | 2.36M/526M [00:00<00:22, 23.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   1%|          | 5.64M/526M [00:00<00:18, 28.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   2%|         | 9.04M/526M [00:00<00:17, 29.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   2%|         | 12.3M/526M [00:00<00:16, 30.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   3%|         | 16.3M/526M [00:00<00:15, 33.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   4%|         | 19.7M/526M [00:00<00:15, 32.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   4%|         | 23.1M/526M [00:00<00:15, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   5%|         | 26.3M/526M [00:00<00:15, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   6%|         | 29.6M/526M [00:00<00:15, 32.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   6%|         | 33.3M/526M [00:01<00:15, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   7%|         | 36.6M/526M [00:01<00:15, 32.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   8%|         | 39.8M/526M [00:01<00:15, 31.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   8%|         | 43.5M/526M [00:01<00:14, 32.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:   9%|         | 47.2M/526M [00:01<00:14, 33.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  10%|         | 50.9M/526M [00:01<00:14, 33.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  10%|         | 54.4M/526M [00:01<00:14, 33.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  11%|         | 57.8M/526M [00:01<00:14, 33.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  12%|        | 61.2M/526M [00:01<00:14, 32.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  12%|        | 64.5M/526M [00:01<00:14, 32.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  13%|        | 67.8M/526M [00:02<00:14, 31.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  14%|        | 71.2M/526M [00:02<00:14, 31.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  14%|        | 75.0M/526M [00:02<00:13, 33.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  15%|        | 78.4M/526M [00:02<00:13, 32.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  16%|        | 82.3M/526M [00:02<00:13, 33.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  16%|        | 86.0M/526M [00:02<00:13, 33.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  17%|        | 89.8M/526M [00:02<00:13, 33.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  18%|        | 93.8M/526M [00:02<00:12, 34.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  19%|        | 97.4M/526M [00:02<00:12, 34.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  19%|        | 101M/526M [00:03<00:12, 34.3MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  20%|        | 105M/526M [00:03<00:12, 33.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  21%|        | 108M/526M [00:03<00:12, 32.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  21%|        | 111M/526M [00:03<00:13, 30.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  22%|       | 115M/526M [00:03<00:12, 32.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  23%|       | 119M/526M [00:03<00:12, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  23%|       | 122M/526M [00:03<00:12, 32.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  24%|       | 126M/526M [00:03<00:12, 32.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  25%|       | 129M/526M [00:03<00:12, 31.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  25%|       | 132M/526M [00:04<00:12, 32.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  26%|       | 136M/526M [00:04<00:12, 32.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  26%|       | 139M/526M [00:04<00:12, 32.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  27%|       | 142M/526M [00:04<00:12, 31.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  28%|       | 146M/526M [00:04<00:11, 31.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  28%|       | 149M/526M [00:04<00:12, 30.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  29%|       | 153M/526M [00:04<00:11, 31.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  30%|       | 156M/526M [00:04<00:12, 30.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  30%|       | 159M/526M [00:04<00:11, 31.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  31%|       | 163M/526M [00:05<00:11, 32.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  32%|      | 167M/526M [00:05<00:11, 32.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  32%|      | 170M/526M [00:05<00:11, 32.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  33%|      | 173M/526M [00:05<00:13, 26.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  34%|      | 177M/526M [00:05<00:12, 28.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  34%|      | 180M/526M [00:05<00:12, 28.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  35%|      | 183M/526M [00:05<00:12, 27.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  35%|      | 186M/526M [00:05<00:12, 27.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  36%|      | 189M/526M [00:05<00:11, 28.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  37%|      | 193M/526M [00:06<00:10, 30.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  37%|      | 196M/526M [00:06<00:10, 30.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  38%|      | 199M/526M [00:06<00:10, 30.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  38%|      | 202M/526M [00:06<00:11, 29.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  39%|      | 205M/526M [00:06<00:10, 29.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  40%|      | 208M/526M [00:06<00:10, 29.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  40%|      | 211M/526M [00:06<00:10, 30.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  41%|      | 215M/526M [00:06<00:10, 30.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  41%|     | 218M/526M [00:06<00:09, 31.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  42%|     | 221M/526M [00:07<00:09, 31.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  43%|     | 224M/526M [00:07<00:10, 28.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  43%|     | 227M/526M [00:07<00:11, 26.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  44%|     | 231M/526M [00:07<00:10, 28.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  44%|     | 234M/526M [00:07<00:11, 24.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  45%|     | 238M/526M [00:07<00:10, 27.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  46%|     | 241M/526M [00:07<00:10, 27.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  46%|     | 243M/526M [00:07<00:11, 24.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  47%|     | 246M/526M [00:08<00:11, 25.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  47%|     | 249M/526M [00:08<00:10, 25.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  48%|     | 252M/526M [00:08<00:10, 25.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  48%|     | 255M/526M [00:08<00:10, 27.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  49%|     | 258M/526M [00:08<00:09, 27.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  50%|     | 261M/526M [00:08<00:09, 28.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  50%|     | 264M/526M [00:08<00:09, 28.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  51%|     | 267M/526M [00:08<00:09, 28.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  51%|     | 270M/526M [00:08<00:09, 26.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  52%|    | 272M/526M [00:08<00:09, 26.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  52%|    | 275M/526M [00:09<00:09, 26.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  53%|    | 278M/526M [00:09<00:09, 25.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  53%|    | 281M/526M [00:09<00:09, 26.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  54%|    | 284M/526M [00:09<00:08, 28.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  55%|    | 287M/526M [00:09<00:08, 28.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  55%|    | 290M/526M [00:09<00:08, 27.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  56%|    | 293M/526M [00:09<00:08, 28.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  56%|    | 296M/526M [00:09<00:07, 28.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  57%|    | 300M/526M [00:09<00:07, 29.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  58%|    | 303M/526M [00:10<00:11, 18.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  58%|    | 306M/526M [00:10<00:10, 21.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  59%|    | 309M/526M [00:10<00:09, 23.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  59%|    | 312M/526M [00:10<00:08, 24.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  60%|    | 315M/526M [00:10<00:08, 25.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  60%|    | 318M/526M [00:10<00:07, 27.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  61%|    | 322M/526M [00:10<00:07, 29.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  62%|   | 325M/526M [00:10<00:06, 29.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  62%|   | 328M/526M [00:11<00:06, 29.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  63%|   | 331M/526M [00:11<00:06, 30.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  64%|   | 334M/526M [00:11<00:06, 30.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  64%|   | 338M/526M [00:11<00:07, 25.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  65%|   | 341M/526M [00:11<00:06, 26.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  65%|   | 344M/526M [00:11<00:06, 27.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  66%|   | 347M/526M [00:11<00:06, 28.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  67%|   | 350M/526M [00:11<00:05, 29.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  67%|   | 353M/526M [00:11<00:05, 29.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  68%|   | 357M/526M [00:12<00:05, 30.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  68%|   | 360M/526M [00:12<00:05, 31.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  69%|   | 363M/526M [00:12<00:05, 27.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  70%|   | 367M/526M [00:12<00:05, 29.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  70%|   | 370M/526M [00:12<00:05, 30.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  71%|   | 374M/526M [00:12<00:04, 31.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  72%|  | 377M/526M [00:12<00:04, 31.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  72%|  | 380M/526M [00:12<00:04, 32.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  73%|  | 384M/526M [00:12<00:04, 32.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  74%|  | 387M/526M [00:13<00:04, 32.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  74%|  | 390M/526M [00:13<00:04, 32.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  75%|  | 394M/526M [00:13<00:04, 32.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  75%|  | 397M/526M [00:13<00:04, 31.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  76%|  | 401M/526M [00:13<00:03, 32.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  77%|  | 404M/526M [00:13<00:03, 33.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  77%|  | 408M/526M [00:13<00:03, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  78%|  | 411M/526M [00:13<00:03, 32.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  79%|  | 414M/526M [00:13<00:03, 32.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  79%|  | 418M/526M [00:13<00:03, 32.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  80%|  | 421M/526M [00:14<00:03, 32.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  81%|  | 424M/526M [00:14<00:03, 32.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  81%| | 428M/526M [00:14<00:03, 32.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  82%| | 431M/526M [00:14<00:03, 31.7MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  83%| | 434M/526M [00:14<00:02, 31.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  83%| | 438M/526M [00:14<00:02, 31.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  84%| | 441M/526M [00:14<00:02, 31.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  84%| | 444M/526M [00:14<00:02, 31.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  85%| | 448M/526M [00:14<00:02, 31.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  86%| | 451M/526M [00:15<00:02, 31.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  86%| | 454M/526M [00:15<00:02, 31.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  87%| | 458M/526M [00:15<00:02, 32.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  88%| | 461M/526M [00:15<00:02, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  88%| | 464M/526M [00:15<00:01, 32.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  89%| | 468M/526M [00:15<00:01, 32.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  90%| | 471M/526M [00:15<00:01, 33.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  90%| | 475M/526M [00:15<00:01, 33.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  91%| | 478M/526M [00:15<00:01, 32.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  92%|| 482M/526M [00:16<00:01, 27.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  92%|| 485M/526M [00:16<00:01, 27.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  93%|| 488M/526M [00:16<00:01, 28.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  93%|| 491M/526M [00:16<00:01, 28.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  94%|| 494M/526M [00:16<00:01, 29.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  94%|| 497M/526M [00:16<00:00, 29.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  95%|| 500M/526M [00:16<00:00, 30.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  96%|| 503M/526M [00:16<00:00, 30.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  96%|| 507M/526M [00:16<00:00, 30.5MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  97%|| 510M/526M [00:16<00:00, 31.1MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  98%|| 513M/526M [00:17<00:00, 31.3MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  98%|| 517M/526M [00:17<00:00, 31.8MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  99%|| 520M/526M [00:17<00:00, 31.6MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip:  99%|| 523M/526M [00:17<00:00, 31.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.9.0/models/default.zip: 100%|| 526M/526M [00:17<00:00, 30.1MB/s]\n",
      "2024-11-20 15:31:06 INFO: Downloaded file to C:\\Users\\Ant\\stanza_resources\\en\\default.zip\n",
      "2024-11-20 15:31:13 INFO: Finished downloading models and saved to C:\\Users\\Ant\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "! textattack list models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhNIugCuGegY"
   },
   "source": [
    "You can use these models as it is by referring to their name. However for the purpose of this practical we are going to train our model from scratch.\n",
    "\n",
    "TextAttack integrates directly with [transformers](https://github.com/huggingface/transformers/) and [datasets](https://github.com/huggingface/datasets) to train any of the `transformers` pre-trained models on datasets from `datasets`.\n",
    "\n",
    "Let's use the Rotten Tomatoes Movie Review dataset: it's relatively short, and showcases the key features of `textattack train`. Let's take a look at the dataset using `textattack peek-dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spS2eW5WseoG",
    "outputId": "52c15f6c-f056-4ba2-bf39-864cdf575883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \n",
      "\n",
      "things really get weird , though not particularly scary : the movie is all portent and no content . \n",
      "\n",
      "\t 1      (4265)\n",
      "\t 0      (4265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ant\\.cache\\huggingface\\hub\\datasets--rotten_tomatoes. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "\n",
      "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]\n",
      "Generating train split: 100%|| 8530/8530 [00:00<00:00, 186800.89 examples/s]\n",
      "\n",
      "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]\n",
      "Generating validation split: 100%|| 1066/1066 [00:00<00:00, 351946.48 examples/s]\n",
      "\n",
      "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]\n",
      "Generating test split: 100%|| 1066/1066 [00:00<?, ? examples/s]\n",
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
      "textattack: Number of samples: \u001b[94m8530\u001b[0m\n",
      "textattack: Number of words per input:\n",
      "textattack: \ttotal:   \u001b[94m157755\u001b[0m\n",
      "textattack: \tmean:    \u001b[94m18.49\u001b[0m\n",
      "textattack: \tstd:     \u001b[94m8.58\u001b[0m\n",
      "textattack: \tmin:     \u001b[94m1\u001b[0m\n",
      "textattack: \tmax:     \u001b[94m51\u001b[0m\n",
      "textattack: Dataset lowercased: \u001b[94mTrue\u001b[0m\n",
      "textattack: First sample:\n",
      "textattack: Last sample:\n",
      "textattack: Found 2 distinct outputs.\n",
      "textattack: Most common outputs:\n"
     ]
    }
   ],
   "source": [
    "!textattack peek-dataset --dataset-from-huggingface rotten_tomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uguqpjnLseoI"
   },
   "source": [
    "The dataset looks good! It's lowercased already, so we'll make sure our model is uncased. The longest input is 51 words, so we can cap our maximum sequence length (`--model-max-length`) at 64.\n",
    "\n",
    "We'll train [`distilbert-base-uncased`](https://huggingface.co/transformers/model_doc/distilbert.html), since it's a relatively small model, and a good example of how we integrate with `transformers`.\n",
    "\n",
    "So we have our command:\n",
    "\n",
    "```bash\n",
    "textattack train                      \\ # Train a model with TextAttack\n",
    "    --model distilbert-base-uncased   \\ # Using distilbert, uncased version, from `transformers`\n",
    "    --dataset rotten_tomatoes         \\ # On the Rotten Tomatoes dataset\n",
    "    --model-num-labels 2              \\ # That has 2 labels\n",
    "    --model-max-length 64             \\ # With a maximum sequence length of 64\n",
    "    --per-device-train-batch-size 128 \\ # And batch size of 128\n",
    "    --num-epochs 3                    \\ # For 3 epochs\n",
    "```\n",
    "\n",
    "Now let's run it (please remember to use GPU if you have access):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BY33W9aWseoI",
    "outputId": "17b3bc8f-2d60-446a-bb3c-37d73d8125f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-30 08:37:12.125309: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-30 08:37:12.174355: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-30 08:37:12.174902: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-30 08:37:13.063631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-uncased\n",
      "config.json: 100% 483/483 [00:00<00:00, 347kB/s]\n",
      "model.safetensors: 100% 268M/268M [00:01<00:00, 244MB/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 323kB/s]\n",
      "vocab.txt: 100% 232k/232k [00:00<00:00, 1.76MB/s]\n",
      "tokenizer.json: 100% 466k/466k [00:00<00:00, 6.89MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
      "\u001b[34;1mtextattack\u001b[0m: Writing logs to ./outputs/2024-09-30-08-37-16-508338/train_log.txt.\n",
      "\u001b[34;1mtextattack\u001b[0m: Wrote original training args to ./outputs/2024-09-30-08-37-16-508338/training_args.json.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n",
      "\u001b[34;1mtextattack\u001b[0m:   Num examples = 8530\n",
      "\u001b[34;1mtextattack\u001b[0m:   Num epochs = 3\n",
      "\u001b[34;1mtextattack\u001b[0m:   Num clean epochs = 3\n",
      "\u001b[34;1mtextattack\u001b[0m:   Instantaneous batch size per device = 128\n",
      "\u001b[34;1mtextattack\u001b[0m:   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "\u001b[34;1mtextattack\u001b[0m:   Gradient accumulation steps = 1\n",
      "\u001b[34;1mtextattack\u001b[0m:   Total optimization steps = 201\n",
      "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
      "\u001b[34;1mtextattack\u001b[0m: Epoch 1\n",
      "\u001b[34;1mtextattack\u001b[0m: Running clean epoch 1/3\n",
      "Loss 0.68512: 100% 67/67 [00:40<00:00,  1.64it/s]\n",
      "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 55.87%\n",
      "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 69.04%\n",
      "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2024-09-30-08-37-16-508338/best_model/\n",
      "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
      "\u001b[34;1mtextattack\u001b[0m: Epoch 2\n",
      "\u001b[34;1mtextattack\u001b[0m: Running clean epoch 2/3\n",
      "Loss 0.57343: 100% 67/67 [00:42<00:00,  1.56it/s]\n",
      "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 79.88%\n",
      "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 83.58%\n",
      "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2024-09-30-08-37-16-508338/best_model/\n",
      "\u001b[34;1mtextattack\u001b[0m: ==========================================================\n",
      "\u001b[34;1mtextattack\u001b[0m: Epoch 3\n",
      "\u001b[34;1mtextattack\u001b[0m: Running clean epoch 3/3\n",
      "Loss 0.49234: 100% 67/67 [00:43<00:00,  1.54it/s]\n",
      "\u001b[34;1mtextattack\u001b[0m: Train accuracy: 86.14%\n",
      "\u001b[34;1mtextattack\u001b[0m: Eval accuracy: 85.65%\n",
      "\u001b[34;1mtextattack\u001b[0m: Best score found. Saved model to ./outputs/2024-09-30-08-37-16-508338/best_model/\n",
      "\u001b[34;1mtextattack\u001b[0m: Wrote README to ./outputs/2024-09-30-08-37-16-508338/README.md.\n"
     ]
    }
   ],
   "source": [
    "!textattack train --model-name-or-path distilbert-base-uncased --dataset rotten_tomatoes --model-num-labels 2 --model-max-length 64 --per-device-train-batch-size 128 --num-epochs 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xzv3BGLseoI"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We successfully fine-tuned `distilbert-base-cased` for 3 epochs. Now let's evaluate it using `textattack eval`. This is as simple as providing the path to the pretrained model (that you just obtain from running the above command!) to `--model`, along with the number of evaluation samples. `textattack eval` will automatically load the evaluation data from training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGYR_W6DseoJ",
    "outputId": "b72af7cc-f415-4769-f007-3f2668acb181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-30 08:47:31.292310: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-30 08:47:31.341401: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-30 08:47:31.342146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-30 08:47:32.287553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "\u001b[34;1mtextattack\u001b[0m: Got 1000 predictions.\n",
      "\u001b[34;1mtextattack\u001b[0m: Correct 847/1000 (\u001b[94m84.70%\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "!textattack eval --num-examples 1000 --model ./outputs/2024-09-30-08-37-16-508338/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFPkCZShseoJ"
   },
   "source": [
    "Awesome -- we were able to train a model up to 84.4% accuracy on the test dataset  with only a single command!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWglEuvUseoK"
   },
   "source": [
    "## Attack\n",
    "\n",
    "Finally, let's attack our pre-trained model. We can do this the same way as before (by providing the path to the pretrained model to `--model`). For our attack, let's use the \"TextFooler\" attack recipe, from the paper [\"Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment\" (Jin et al, 2019)](https://arxiv.org/abs/1907.11932). We can do this by passing `--recipe textfooler` to `textattack attack`.\n",
    "\n",
    "> *Warning*: We're printing out 100 examples and, if the attack succeeds, their perturbations. The output of this command is going to be quite long!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vL-Bo1bgseoK",
    "outputId": "e6e175c9-d1ad-40a3-bf77-3facc3b84c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-15 18:08:50.066191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[34;1mtextattack\u001b[0m: Downloading https://textattack.s3.amazonaws.com/word_embeddings/paragramcf.\n",
      "100% 481M/481M [00:12<00:00, 37.6MB/s]\n",
      "\u001b[34;1mtextattack\u001b[0m: Unzipping file /root/.cache/textattack/tmpqqu16993.zip to /root/.cache/textattack/word_embeddings/paragramcf.\n",
      "\u001b[34;1mtextattack\u001b[0m: Successfully saved word_embeddings/paragramcf to cache.\n",
      "\u001b[34;1mtextattack\u001b[0m: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n",
      "  0% 0/100 [00:00<?, ?it/s]2023-10-15 18:09:45.209737: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-10-15 18:09:46.534633: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
      "2023-10-15 18:09:46.568969: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
      "2023-10-15 18:09:46.605081: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
      "2023-10-15 18:09:46.641544: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
      "2023-10-15 18:09:46.678749: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 34133760 exceeds 10% of free system memory.\n",
      "  1% 1/100 [00:30<49:57, 30.28s/it]--------------------------------------------- Result 1 ---------------------------------------------\n",
      "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (53%)\u001b[0m\n",
      "\n",
      "\u001b[92mlovingly\u001b[0m photographed in the manner of a golden book sprung to life , stuart little 2 manages \u001b[92msweetness\u001b[0m largely without stickiness .\n",
      "\n",
      "\u001b[91maffectionately\u001b[0m photographed in the manner of a golden book sprung to life , stuart little 2 manages \u001b[91msweetie\u001b[0m largely without stickiness .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   2% 2/100 [00:31<25:25, 15.57s/it]--------------------------------------------- Result 2 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (95%)\u001b[0m\n",
      "\n",
      "consistently \u001b[92mclever\u001b[0m and \u001b[92msuspenseful\u001b[0m .\n",
      "\n",
      "consistently \u001b[91mmalin\u001b[0m and \u001b[91mnightmarish\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:   2% 2/100 [00:31<25:25, 15.57s/it]--------------------------------------------- Result 3 ---------------------------------------------\n",
      "\u001b[91mNegative (90%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "it's like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 1 / 3:   4% 4/100 [00:31<12:34,  7.86s/it]--------------------------------------------- Result 4 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (75%)\u001b[0m\n",
      "\n",
      "the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with \u001b[92mtremendous\u001b[0m \u001b[92mskill\u001b[0m .\n",
      "\n",
      "the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with \u001b[91mstupendous\u001b[0m \u001b[91mjurisdictional\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 1 / 4:   4% 4/100 [00:31<12:34,  7.86s/it]--------------------------------------------- Result 5 ---------------------------------------------\n",
      "\u001b[91mNegative (76%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "red dragon \" never cuts corners .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 2 / 5:   6% 6/100 [00:31<08:14,  5.26s/it]--------------------------------------------- Result 6 ---------------------------------------------\n",
      "\u001b[92mPositive (63%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
      "\n",
      "fresnadillo has something serious to say about the \u001b[92mways\u001b[0m in which extravagant chance can distort our perspective and throw us off the path of good sense .\n",
      "\n",
      "fresnadillo has something serious to say about the \u001b[91mmanner\u001b[0m in which extravagant chance can distort our perspective and throw us off the path of good sense .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 2 / 6:   6% 6/100 [00:31<08:14,  5.26s/it]--------------------------------------------- Result 7 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (65%)\u001b[0m\n",
      "\n",
      "throws in enough clever and \u001b[92munexpected\u001b[0m \u001b[92mtwists\u001b[0m to make the formula feel fresh .\n",
      "\n",
      "throws in enough clever and \u001b[91munwanted\u001b[0m \u001b[91mtendrils\u001b[0m to make the formula feel fresh .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 2 / 7:   8% 8/100 [00:31<06:04,  3.96s/it]--------------------------------------------- Result 8 ---------------------------------------------\n",
      "\u001b[91mNegative (78%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "weighty and ponderous but every bit as filling as the treat of the title .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 3 / 8:   8% 8/100 [00:31<06:04,  3.96s/it]--------------------------------------------- Result 9 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (66%)\u001b[0m\n",
      "\n",
      "a \u001b[92mreal\u001b[0m audience-pleaser that will \u001b[92mstrike\u001b[0m a \u001b[92mchord\u001b[0m with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
      "\n",
      "a \u001b[91mactual\u001b[0m audience-pleaser that will \u001b[91mslugged\u001b[0m a \u001b[91mchords\u001b[0m with anyone who's ever waited in a doctor's office , emergency room , hospital bed or insurance company office .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 6 / 0 / 3 / 9:  10% 10/100 [00:32<04:48,  3.21s/it]--------------------------------------------- Result 10 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
      "\n",
      "generates an \u001b[92menormous\u001b[0m feeling of empathy for its characters .\n",
      "\n",
      "generates an \u001b[91mdreaded\u001b[0m feeling of empathy for its characters .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 7 / 0 / 3 / 10:  10% 10/100 [00:32<04:48,  3.21s/it]--------------------------------------------- Result 11 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
      "\n",
      "exposing the ways we fool ourselves is one hour photo's real \u001b[92mstrength\u001b[0m .\n",
      "\n",
      "exposing the ways we fool ourselves is one hour photo's real \u001b[91mstrenght\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 8 / 0 / 3 / 11:  12% 12/100 [00:32<03:57,  2.70s/it]--------------------------------------------- Result 12 ---------------------------------------------\n",
      "\u001b[92mPositive (58%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
      "\n",
      "it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful \u001b[92mview\u001b[0m of american life .\n",
      "\n",
      "it's up to you to decide whether to admire these people's dedication to their cause or be repelled by their dogmatism , manipulativeness and narrow , fearful \u001b[91mviewed\u001b[0m of american life .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 3 / 12:  12% 12/100 [00:32<03:57,  2.70s/it]--------------------------------------------- Result 13 ---------------------------------------------\n",
      "\u001b[91mNegative (84%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "mostly , [goldbacher] just lets her complicated characters be unruly , confusing and , through it all , human .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 4 / 13:  14% 14/100 [00:32<03:19,  2.32s/it]--------------------------------------------- Result 14 ---------------------------------------------\n",
      "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
      "\n",
      ". . . \u001b[92mquite\u001b[0m \u001b[92mgood\u001b[0m at providing some good old fashioned spooks .\n",
      "\n",
      ". . . \u001b[91mtoo\u001b[0m \u001b[91mbestest\u001b[0m at providing some good old fashioned spooks .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 10 / 0 / 4 / 14:  14% 14/100 [00:32<03:20,  2.33s/it]--------------------------------------------- Result 15 ---------------------------------------------\n",
      "\u001b[91mNegative (95%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "at its worst , the movie is pretty diverting ; the pity is that it rarely achieves its best .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 10 / 0 / 5 / 15:  16% 16/100 [00:32<02:53,  2.06s/it]--------------------------------------------- Result 16 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (77%)\u001b[0m\n",
      "\n",
      "scherfig's light-hearted \u001b[92mprofile\u001b[0m of \u001b[92memotional\u001b[0m \u001b[92mdesperation\u001b[0m is achingly \u001b[92mhonest\u001b[0m and \u001b[92mdelightfully\u001b[0m cheeky .\n",
      "\n",
      "scherfig's light-hearted \u001b[91mdescribe\u001b[0m of \u001b[91mpsychiatric\u001b[0m \u001b[91mwoe\u001b[0m is achingly \u001b[91mfranc\u001b[0m and \u001b[91mblithely\u001b[0m cheeky .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 11 / 0 / 5 / 16:  16% 16/100 [00:32<02:53,  2.06s/it]--------------------------------------------- Result 17 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (78%)\u001b[0m\n",
      "\n",
      "a \u001b[92mjourney\u001b[0m \u001b[92mspanning\u001b[0m nearly three decades of bittersweet camaraderie and history , in which we feel that we truly know what makes holly and marina tick , and our \u001b[92mhearts\u001b[0m go out to them as both continue to negotiate their \u001b[92mimperfect\u001b[0m , love-hate relationship .\n",
      "\n",
      "a \u001b[91mtrekking\u001b[0m \u001b[91mexpectancy\u001b[0m nearly three decades of bittersweet camaraderie and history , in which we feel that we truly know what makes holly and marina tick , and our \u001b[91mcoeur\u001b[0m go out to them as both continue to negotiate their \u001b[91minsufficient\u001b[0m , love-hate relationship .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 12 / 0 / 5 / 17:  18% 18/100 [00:33<02:33,  1.87s/it]--------------------------------------------- Result 18 ---------------------------------------------\n",
      "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (62%)\u001b[0m\n",
      "\n",
      "the \u001b[92mwonderfully\u001b[0m \u001b[92mlush\u001b[0m morvern callar is pure punk existentialism , and ms . ramsay and her co-writer , liana dognini , have dramatized the alan warner novel , which itself felt like an answer to irvine welsh's book trainspotting .\n",
      "\n",
      "the \u001b[91mappallingly\u001b[0m \u001b[91mlanguid\u001b[0m morvern callar is pure punk existentialism , and ms . ramsay and her co-writer , liana dognini , have dramatized the alan warner novel , which itself felt like an answer to irvine welsh's book trainspotting .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 13 / 0 / 5 / 18:  18% 18/100 [00:33<02:33,  1.87s/it]--------------------------------------------- Result 19 ---------------------------------------------\n",
      "\u001b[92mPositive (54%)\u001b[0m --> \u001b[91mNegative (78%)\u001b[0m\n",
      "\n",
      "as it turns out , you can go \u001b[92mhome\u001b[0m again .\n",
      "\n",
      "as it turns out , you can go \u001b[91mhabitation\u001b[0m again .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 14 / 0 / 5 / 19:  20% 20/100 [00:33<02:15,  1.70s/it]--------------------------------------------- Result 20 ---------------------------------------------\n",
      "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (83%)\u001b[0m\n",
      "\n",
      "you've already seen city by the sea under a variety of titles , but it's \u001b[92mworth\u001b[0m yet another visit .\n",
      "\n",
      "you've already seen city by the sea under a variety of titles , but it's \u001b[91mchastisement\u001b[0m yet another visit .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 15 / 0 / 5 / 20:  20% 20/100 [00:33<02:15,  1.70s/it]--------------------------------------------- Result 21 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (63%)\u001b[0m\n",
      "\n",
      "this kind of hands-on \u001b[92mstorytelling\u001b[0m is ultimately what \u001b[92mmakes\u001b[0m shanghai ghetto move beyond a \u001b[92mgood\u001b[0m , dry , reliable textbook and what allows it to rank with its \u001b[92mworthy\u001b[0m predecessors .\n",
      "\n",
      "this kind of hands-on \u001b[91mmyth\u001b[0m is ultimately what \u001b[91mdo\u001b[0m shanghai ghetto move beyond a \u001b[91msuitable\u001b[0m , dry , reliable textbook and what allows it to rank with its \u001b[91mlegitimate\u001b[0m predecessors .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 16 / 0 / 5 / 21:  22% 22/100 [00:34<02:02,  1.57s/it]--------------------------------------------- Result 22 ---------------------------------------------\n",
      "\u001b[92mPositive (72%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
      "\n",
      "making such a tragedy the backdrop to a love story risks trivializing it , though chouraqui no doubt intended the film to affirm love's power to \u001b[92mhelp\u001b[0m people endure almost unimaginable horror .\n",
      "\n",
      "making such a tragedy the backdrop to a love story risks trivializing it , though chouraqui no doubt intended the film to affirm love's power to \u001b[91msuccor\u001b[0m people endure almost unimaginable horror .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 17 / 0 / 5 / 22:  22% 22/100 [00:34<02:02,  1.57s/it]--------------------------------------------- Result 23 ---------------------------------------------\n",
      "\u001b[91mNegative (51%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "grown-up quibbles are beside the point here . the little girls understand , and mccracken knows that's all that matters .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 17 / 0 / 6 / 23:  24% 24/100 [00:34<01:50,  1.46s/it]--------------------------------------------- Result 24 ---------------------------------------------\n",
      "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
      "\n",
      "a \u001b[92mpowerful\u001b[0m , chilling , and affecting \u001b[92mstudy\u001b[0m of one man's \u001b[92mdying\u001b[0m \u001b[92mfall\u001b[0m .\n",
      "\n",
      "a \u001b[91mconclusive\u001b[0m , chilling , and affecting \u001b[91mresearch\u001b[0m of one man's \u001b[91mfatalities\u001b[0m \u001b[91mdeclined\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 18 / 0 / 6 / 24:  24% 24/100 [00:34<01:50,  1.46s/it]--------------------------------------------- Result 25 ---------------------------------------------\n",
      "\u001b[92mPositive (68%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
      "\n",
      "this is a \u001b[92mfascinating\u001b[0m film because there is no clear-cut hero and no all-out villain .\n",
      "\n",
      "this is a \u001b[91minteresting\u001b[0m film because there is no clear-cut hero and no all-out villain .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 19 / 0 / 6 / 25:  26% 26/100 [00:35<01:40,  1.35s/it]--------------------------------------------- Result 26 ---------------------------------------------\n",
      "\u001b[92mPositive (80%)\u001b[0m --> \u001b[91mNegative (89%)\u001b[0m\n",
      "\n",
      "a dreadful day in irish history is given \u001b[92mpassionate\u001b[0m , if somewhat flawed , treatment .\n",
      "\n",
      "a dreadful day in irish history is given \u001b[91mgreedy\u001b[0m , if somewhat flawed , treatment .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 20 / 0 / 6 / 26:  26% 26/100 [00:35<01:40,  1.35s/it]--------------------------------------------- Result 27 ---------------------------------------------\n",
      "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (88%)\u001b[0m\n",
      "\n",
      ". . . a \u001b[92mgood\u001b[0m film that must have baffled the folks in the marketing department .\n",
      "\n",
      ". . . a \u001b[91mok\u001b[0m film that must have baffled the folks in the marketing department .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 21 / 0 / 6 / 27:  28% 28/100 [00:35<01:32,  1.28s/it]--------------------------------------------- Result 28 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
      "\n",
      ". . . is \u001b[92mfunny\u001b[0m in the \u001b[92mway\u001b[0m that makes you ache with sadness ( the way chekhov is funny ) , \u001b[92mprofound\u001b[0m without ever being self-important , \u001b[92mwarm\u001b[0m without ever succumbing to sentimentality .\n",
      "\n",
      ". . . is \u001b[91moutlandish\u001b[0m in the \u001b[91mitineraries\u001b[0m that makes you ache with sadness ( the way chekhov is funny ) , \u001b[91mshum\u001b[0m without ever being self-important , \u001b[91mwarmer\u001b[0m without ever succumbing to sentimentality .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 22 / 0 / 6 / 28:  28% 28/100 [00:35<01:32,  1.28s/it]--------------------------------------------- Result 29 ---------------------------------------------\n",
      "\u001b[91mNegative (96%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "devotees of star trek ii : the wrath of khan will feel a nagging sense of deja vu , and the grandeur of the best next generation episodes is lacking .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 22 / 0 / 7 / 29:  30% 30/100 [00:37<01:26,  1.24s/it]--------------------------------------------- Result 30 ---------------------------------------------\n",
      "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91m[FAILED]\u001b[0m\n",
      "\n",
      "a soul-stirring documentary about the israeli/palestinian conflict as revealed through the eyes of some children who remain curious about each other against all odds .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 22 / 1 / 7 / 30:  30% 30/100 [00:37<01:26,  1.24s/it]--------------------------------------------- Result 31 ---------------------------------------------\n",
      "\u001b[92mPositive (84%)\u001b[0m --> \u001b[91mNegative (70%)\u001b[0m\n",
      "\n",
      "what's so \u001b[92mstriking\u001b[0m about jolie's performance is that she never lets her character become a caricature -- not even with that radioactive hair .\n",
      "\n",
      "what's so \u001b[91mstaggering\u001b[0m about jolie's performance is that she never lets her character become a caricature -- not even with that radioactive hair .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 23 / 1 / 7 / 31:  32% 32/100 [00:37<01:19,  1.17s/it]--------------------------------------------- Result 32 ---------------------------------------------\n",
      "\u001b[91mNegative (82%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "the main story . . . is compelling enough , but it's difficult to shrug off the annoyance of that chatty fish .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 23 / 1 / 8 / 32:  32% 32/100 [00:37<01:19,  1.17s/it]--------------------------------------------- Result 33 ---------------------------------------------\n",
      "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (91%)\u001b[0m\n",
      "\n",
      "the performances are \u001b[92mimmaculate\u001b[0m , with roussillon providing comic relief .\n",
      "\n",
      "the performances are \u001b[91mblameless\u001b[0m , with roussillon providing comic relief .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 24 / 1 / 8 / 33:  34% 34/100 [00:37<01:13,  1.12s/it]--------------------------------------------- Result 34 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (55%)\u001b[0m\n",
      "\n",
      "kinnear . . . \u001b[92mgives\u001b[0m his best screen performance with an oddly \u001b[92mwinning\u001b[0m \u001b[92mportrayal\u001b[0m of one of life's \u001b[92multimate\u001b[0m losers .\n",
      "\n",
      "kinnear . . . \u001b[91massigns\u001b[0m his best screen performance with an oddly \u001b[91mearns\u001b[0m \u001b[91msimilarity\u001b[0m of one of life's \u001b[91mfinal\u001b[0m losers .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 25 / 1 / 8 / 34:  34% 34/100 [00:37<01:13,  1.12s/it]--------------------------------------------- Result 35 ---------------------------------------------\n",
      "\u001b[91mNegative (80%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "hugh grant , who has a good line in charm , has never been more charming than in about a boy .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 25 / 1 / 9 / 35:  36% 36/100 [00:38<01:07,  1.06s/it]--------------------------------------------- Result 36 ---------------------------------------------\n",
      "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (80%)\u001b[0m\n",
      "\n",
      "there's a lot of tooth in roger dodger . but what's \u001b[92mnice\u001b[0m is that there's a casual intelligence that permeates the script .\n",
      "\n",
      "there's a lot of tooth in roger dodger . but what's \u001b[91mleggy\u001b[0m is that there's a casual intelligence that permeates the script .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 26 / 1 / 9 / 36:  36% 36/100 [00:38<01:07,  1.06s/it]--------------------------------------------- Result 37 ---------------------------------------------\n",
      "\u001b[91mNegative (74%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "reminiscent of alfred hitchcock's thrillers , most of the scary parts in 'signs' occur while waiting for things to happen .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 26 / 1 / 10 / 37:  38% 38/100 [00:38<01:02,  1.01s/it]--------------------------------------------- Result 38 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (83%)\u001b[0m\n",
      "\n",
      "one of the \u001b[92mbest\u001b[0m looking and \u001b[92mstylish\u001b[0m \u001b[92manimated\u001b[0m movies in quite a while . . .\n",
      "\n",
      "one of the \u001b[91mstrictest\u001b[0m looking and \u001b[91mtrendy\u001b[0m \u001b[91mabetted\u001b[0m movies in quite a while . . .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 27 / 1 / 10 / 38:  38% 38/100 [00:38<01:02,  1.01s/it]--------------------------------------------- Result 39 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (84%)\u001b[0m\n",
      "\n",
      "its use of the thriller form to examine the labyrinthine ways in which people's lives cross and change , buffeted by events seemingly out of their control , is \u001b[92mintriguing\u001b[0m , \u001b[92mprovocative\u001b[0m stuff .\n",
      "\n",
      "its use of the thriller form to examine the labyrinthine ways in which people's lives cross and change , buffeted by events seemingly out of their control , is \u001b[91mdisconcerting\u001b[0m , \u001b[91mincite\u001b[0m stuff .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 28 / 1 / 10 / 39:  40% 40/100 [00:39<00:58,  1.03it/s]--------------------------------------------- Result 40 ---------------------------------------------\n",
      "\u001b[92mPositive (89%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
      "\n",
      "denver \u001b[92mshould\u001b[0m not get the first and last look at one of the most triumphant performances of vanessa redgrave's career . it deserves to be seen everywhere .\n",
      "\n",
      "denver \u001b[91menvisioned\u001b[0m not get the first and last look at one of the most triumphant performances of vanessa redgrave's career . it deserves to be seen everywhere .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 29 / 1 / 10 / 40:  40% 40/100 [00:39<00:58,  1.02it/s]--------------------------------------------- Result 41 ---------------------------------------------\n",
      "\u001b[91mNegative (65%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "you needn't be steeped in '50s sociology , pop culture or movie lore to appreciate the emotional depth of haynes' work . though haynes' style apes films from the period . . . its message is not rooted in that decade .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 29 / 1 / 11 / 41:  42% 42/100 [00:39<00:54,  1.07it/s]--------------------------------------------- Result 42 ---------------------------------------------\n",
      "\u001b[92mPositive (91%)\u001b[0m --> \u001b[91mNegative (61%)\u001b[0m\n",
      "\n",
      "waiting for godard can be \u001b[92mfruitful\u001b[0m : 'in praise of love' is the director's epitaph for himself .\n",
      "\n",
      "waiting for godard can be \u001b[91mpropitious\u001b[0m : 'in praise of love' is the director's epitaph for himself .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 30 / 1 / 11 / 42:  42% 42/100 [00:39<00:54,  1.07it/s]--------------------------------------------- Result 43 ---------------------------------------------\n",
      "\u001b[92mPositive (93%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
      "\n",
      "a gangster movie with the capacity to \u001b[92msurprise\u001b[0m .\n",
      "\n",
      "a gangster movie with the capacity to \u001b[91mflabbergasted\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 31 / 1 / 11 / 43:  44% 44/100 [00:39<00:50,  1.11it/s]--------------------------------------------- Result 44 ---------------------------------------------\n",
      "\u001b[92mPositive (67%)\u001b[0m --> \u001b[91mNegative (91%)\u001b[0m\n",
      "\n",
      "the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are \u001b[92mworth\u001b[0m the price of admission . . . if \" gory mayhem \" is your idea of a good time .\n",
      "\n",
      "the film has a laundry list of minor shortcomings , but the numerous scenes of gory mayhem are \u001b[91mpriceless\u001b[0m the price of admission . . . if \" gory mayhem \" is your idea of a good time .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 32 / 1 / 11 / 44:  44% 44/100 [00:39<00:50,  1.11it/s]--------------------------------------------- Result 45 ---------------------------------------------\n",
      "\u001b[92mPositive (55%)\u001b[0m --> \u001b[91mNegative (87%)\u001b[0m\n",
      "\n",
      "if not a home run , then at least a \u001b[92msolid\u001b[0m base hit .\n",
      "\n",
      "if not a home run , then at least a \u001b[91mbeefy\u001b[0m base hit .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 33 / 1 / 11 / 45:  46% 46/100 [00:39<00:46,  1.15it/s]--------------------------------------------- Result 46 ---------------------------------------------\n",
      "\u001b[92mPositive (87%)\u001b[0m --> \u001b[91mNegative (76%)\u001b[0m\n",
      "\n",
      "goldmember is \u001b[92mfunny\u001b[0m enough to justify the embarrassment of bringing a barf bag to the moviehouse .\n",
      "\n",
      "goldmember is \u001b[91mcomical\u001b[0m enough to justify the embarrassment of bringing a barf bag to the moviehouse .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 34 / 1 / 11 / 46:  46% 46/100 [00:39<00:46,  1.15it/s]--------------------------------------------- Result 47 ---------------------------------------------\n",
      "\u001b[92mPositive (83%)\u001b[0m --> \u001b[91mNegative (91%)\u001b[0m\n",
      "\n",
      ". . . a fairly disposable yet still \u001b[92mentertaining\u001b[0m b picture .\n",
      "\n",
      ". . . a fairly disposable yet still \u001b[91mdroll\u001b[0m b picture .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 35 / 1 / 11 / 47:  48% 48/100 [00:40<00:43,  1.18it/s]--------------------------------------------- Result 48 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
      "\n",
      "it may not be particularly \u001b[92minnovative\u001b[0m , but the film's crisp , unaffected style and air of gentle \u001b[92mlonging\u001b[0m \u001b[92mmake\u001b[0m it unexpectedly \u001b[92mrewarding\u001b[0m .\n",
      "\n",
      "it may not be particularly \u001b[91mfanciful\u001b[0m , but the film's crisp , unaffected style and air of gentle \u001b[91mvacuuming\u001b[0m \u001b[91mget\u001b[0m it unexpectedly \u001b[91mbounties\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 36 / 1 / 11 / 48:  48% 48/100 [00:40<00:44,  1.18it/s]--------------------------------------------- Result 49 ---------------------------------------------\n",
      "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (79%)\u001b[0m\n",
      "\n",
      "the film \u001b[92mtruly\u001b[0m does rescue [the funk brothers] from motown's shadows . it's about time .\n",
      "\n",
      "the film \u001b[91mawfully\u001b[0m does rescue [the funk brothers] from motown's shadows . it's about time .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 37 / 1 / 11 / 49:  50% 50/100 [00:41<00:41,  1.21it/s]--------------------------------------------- Result 50 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
      "\n",
      "drawing on an \u001b[92mirresistible\u001b[0m , languid romanticism , byler \u001b[92mreveals\u001b[0m the \u001b[92mways\u001b[0m in which a sultry evening or a beer-fueled afternoon in the sun can inspire even the most retiring heart to venture forth .\n",
      "\n",
      "drawing on an \u001b[91mstupendous\u001b[0m , languid romanticism , byler \u001b[91mbetrays\u001b[0m the \u001b[91mmanner\u001b[0m in which a sultry evening or a beer-fueled afternoon in the sun can inspire even the most retiring heart to venture forth .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 38 / 1 / 11 / 50:  50% 50/100 [00:41<00:41,  1.21it/s]--------------------------------------------- Result 51 ---------------------------------------------\n",
      "\u001b[91mNegative (92%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "works because we're never sure if ohlinger's on the level or merely a dying , delusional man trying to get into the history books before he croaks .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 38 / 1 / 12 / 51:  52% 52/100 [00:41<00:38,  1.25it/s]--------------------------------------------- Result 52 ---------------------------------------------\n",
      "\u001b[92mPositive (64%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
      "\n",
      "[scherfig] has made a \u001b[92mmovie\u001b[0m that will leave you wondering about the characters' lives after the clever credits roll .\n",
      "\n",
      "[scherfig] has made a \u001b[91mcine\u001b[0m that will leave you wondering about the characters' lives after the clever credits roll .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 39 / 1 / 12 / 52:  52% 52/100 [00:41<00:38,  1.25it/s]--------------------------------------------- Result 53 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
      "\n",
      "a \u001b[92mheady\u001b[0m , \u001b[92mbiting\u001b[0m , be-bop ride through nighttime manhattan , a loquacious videologue of the \u001b[92mmodern\u001b[0m male and the lengths to which he'll go to weave a protective cocoon around his own ego .\n",
      "\n",
      "a \u001b[91mchoppy\u001b[0m , \u001b[91mgnawing\u001b[0m , be-bop ride through nighttime manhattan , a loquacious videologue of the \u001b[91mupgraded\u001b[0m male and the lengths to which he'll go to weave a protective cocoon around his own ego .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 40 / 1 / 12 / 53:  54% 54/100 [00:42<00:35,  1.28it/s]--------------------------------------------- Result 54 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (56%)\u001b[0m\n",
      "\n",
      "skin of man gets a few cheap shocks from its kids-in-peril theatrics , but it also \u001b[92mtaps\u001b[0m into the \u001b[92mprimal\u001b[0m fears of young people trying to cope with the mysterious and brutal nature of adults .\n",
      "\n",
      "skin of man gets a few cheap shocks from its kids-in-peril theatrics , but it also \u001b[91mfaucets\u001b[0m into the \u001b[91mrudimentary\u001b[0m fears of young people trying to cope with the mysterious and brutal nature of adults .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 41 / 1 / 12 / 54:  54% 54/100 [00:42<00:35,  1.28it/s]--------------------------------------------- Result 55 ---------------------------------------------\n",
      "\u001b[92mPositive (85%)\u001b[0m --> \u001b[91mNegative (66%)\u001b[0m\n",
      "\n",
      "the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a \u001b[92mcool\u001b[0m distance from its material that is deliberately unsettling .\n",
      "\n",
      "the piano teacher is not an easy film . it forces you to watch people doing unpleasant things to each other and themselves , and it maintains a \u001b[91mcopacetic\u001b[0m distance from its material that is deliberately unsettling .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 42 / 1 / 12 / 55:  56% 56/100 [00:42<00:33,  1.32it/s]--------------------------------------------- Result 56 ---------------------------------------------\n",
      "\u001b[92mPositive (96%)\u001b[0m --> \u001b[91mNegative (89%)\u001b[0m\n",
      "\n",
      "as \u001b[92mrefreshing\u001b[0m as a drink from a woodland stream .\n",
      "\n",
      "as \u001b[91mretrofit\u001b[0m as a drink from a woodland stream .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 43 / 1 / 12 / 56:  56% 56/100 [00:42<00:33,  1.32it/s]--------------------------------------------- Result 57 ---------------------------------------------\n",
      "\u001b[92mPositive (62%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
      "\n",
      "williams absolutely nails sy's queasy infatuation and overall \u001b[92mstrangeness\u001b[0m .\n",
      "\n",
      "williams absolutely nails sy's queasy infatuation and overall \u001b[91mennui\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 44 / 1 / 12 / 57:  58% 58/100 [00:42<00:30,  1.36it/s]--------------------------------------------- Result 58 ---------------------------------------------\n",
      "\u001b[92mPositive (63%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
      "\n",
      "can i admit xxx is as deep as a petri dish and as well-characterized as a telephone book but still say it was a guilty \u001b[92mpleasure\u001b[0m ?\n",
      "\n",
      "can i admit xxx is as deep as a petri dish and as well-characterized as a telephone book but still say it was a guilty \u001b[91mpleasures\u001b[0m ?\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 45 / 1 / 12 / 58:  58% 58/100 [00:42<00:30,  1.36it/s]--------------------------------------------- Result 59 ---------------------------------------------\n",
      "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
      "\n",
      "while it's nothing we haven't seen before from murphy , i spy is still fun and \u001b[92menjoyable\u001b[0m and so aggressively silly that it's more than a worthwhile effort .\n",
      "\n",
      "while it's nothing we haven't seen before from murphy , i spy is still fun and \u001b[91mcosy\u001b[0m and so aggressively silly that it's more than a worthwhile effort .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 46 / 1 / 12 / 59:  60% 60/100 [00:43<00:28,  1.39it/s]--------------------------------------------- Result 60 ---------------------------------------------\n",
      "\u001b[92mPositive (57%)\u001b[0m --> \u001b[91mNegative (75%)\u001b[0m\n",
      "\n",
      "by the time it ends in a rush of sequins , flashbulbs , blaring brass and back-stabbing babes , it has said \u001b[92mplenty\u001b[0m about how show business has infiltrated every corner of society -- and not always for the better .\n",
      "\n",
      "by the time it ends in a rush of sequins , flashbulbs , blaring brass and back-stabbing babes , it has said \u001b[91mlots\u001b[0m about how show business has infiltrated every corner of society -- and not always for the better .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 47 / 1 / 12 / 60:  60% 60/100 [00:43<00:28,  1.39it/s]--------------------------------------------- Result 61 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
      "\n",
      "an \u001b[92mintimate\u001b[0m contemplation of two marvelously messy lives .\n",
      "\n",
      "an \u001b[91msqueamish\u001b[0m contemplation of two marvelously messy lives .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 48 / 1 / 12 / 61:  62% 62/100 [00:43<00:26,  1.43it/s]--------------------------------------------- Result 62 ---------------------------------------------\n",
      "\u001b[91mNegative (68%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "rarely has skin looked as beautiful , desirable , even delectable , as it does in trouble every day .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 48 / 1 / 13 / 62:  62% 62/100 [00:43<00:26,  1.43it/s]--------------------------------------------- Result 63 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (54%)\u001b[0m\n",
      "\n",
      "this is one of those rare docs that paints a \u001b[92mgrand\u001b[0m picture of an \u001b[92mera\u001b[0m and \u001b[92mmakes\u001b[0m the \u001b[92mjourney\u001b[0m feel like a \u001b[92mparty\u001b[0m .\n",
      "\n",
      "this is one of those rare docs that paints a \u001b[91mgargantuan\u001b[0m picture of an \u001b[91mtimeframe\u001b[0m and \u001b[91mai\u001b[0m the \u001b[91mtrip\u001b[0m feel like a \u001b[91mportions\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 49 / 1 / 13 / 63:  64% 64/100 [00:44<00:24,  1.45it/s]--------------------------------------------- Result 64 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
      "\n",
      "\u001b[92mpoignant\u001b[0m if familiar story of a young person suspended between two cultures .\n",
      "\n",
      "\u001b[91mdisheartening\u001b[0m if familiar story of a young person suspended between two cultures .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 50 / 1 / 13 / 64:  64% 64/100 [00:44<00:24,  1.45it/s]--------------------------------------------- Result 65 ---------------------------------------------\n",
      "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (95%)\u001b[0m\n",
      "\n",
      "a \u001b[92mmetaphor\u001b[0m for a modern-day urban china searching for its identity .\n",
      "\n",
      "a \u001b[91mclich\u001b[0m for a modern-day urban china searching for its identity .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 51 / 1 / 13 / 65:  66% 66/100 [00:44<00:22,  1.48it/s]--------------------------------------------- Result 66 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (63%)\u001b[0m\n",
      "\n",
      "for all its brooding quality , ash wednesday is \u001b[92msuspenseful\u001b[0m and ultimately unpredictable , with a \u001b[92msterling\u001b[0m ensemble cast .\n",
      "\n",
      "for all its brooding quality , ash wednesday is \u001b[91mcliffhanger\u001b[0m and ultimately unpredictable , with a \u001b[91mstirling\u001b[0m ensemble cast .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 52 / 1 / 13 / 66:  66% 66/100 [00:44<00:22,  1.48it/s]--------------------------------------------- Result 67 ---------------------------------------------\n",
      "\u001b[92mPositive (92%)\u001b[0m --> \u001b[91mNegative (65%)\u001b[0m\n",
      "\n",
      "an odd \u001b[92mdrama\u001b[0m set in the \u001b[92mworld\u001b[0m of lingerie models and bar dancers in the midwest that held my interest precisely because it didn't try to .\n",
      "\n",
      "an odd \u001b[91mcataclysmic\u001b[0m set in the \u001b[91mglobo\u001b[0m of lingerie models and bar dancers in the midwest that held my interest precisely because it didn't try to .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 53 / 1 / 13 / 67:  68% 68/100 [00:44<00:21,  1.52it/s]--------------------------------------------- Result 68 ---------------------------------------------\n",
      "\u001b[92mPositive (80%)\u001b[0m --> \u001b[91mNegative (88%)\u001b[0m\n",
      "\n",
      "the film feels uncomfortably \u001b[92mreal\u001b[0m , its language and locations bearing the unmistakable stamp of authority .\n",
      "\n",
      "the film feels uncomfortably \u001b[91mactual\u001b[0m , its language and locations bearing the unmistakable stamp of authority .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 54 / 1 / 13 / 68:  68% 68/100 [00:44<00:21,  1.52it/s]--------------------------------------------- Result 69 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
      "\n",
      "despite its faults , gangs \u001b[92mexcels\u001b[0m in spectacle and pacing .\n",
      "\n",
      "despite its faults , gangs \u001b[91moverwhelms\u001b[0m in spectacle and pacing .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 55 / 1 / 13 / 69:  70% 70/100 [00:45<00:19,  1.55it/s]--------------------------------------------- Result 70 ---------------------------------------------\n",
      "\u001b[92mPositive (78%)\u001b[0m --> \u001b[91mNegative (70%)\u001b[0m\n",
      "\n",
      "\u001b[92mentertaining\u001b[0m despite its one-joke premise with the thesis that women from venus and men from mars can indeed get together .\n",
      "\n",
      "\u001b[91mamusement\u001b[0m despite its one-joke premise with the thesis that women from venus and men from mars can indeed get together .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 56 / 1 / 13 / 70:  70% 70/100 [00:45<00:19,  1.55it/s]--------------------------------------------- Result 71 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
      "\n",
      "a tightly directed , \u001b[92mhighly\u001b[0m professional film that's old-fashioned in all the best possible ways .\n",
      "\n",
      "a tightly directed , \u001b[91mexcessively\u001b[0m professional film that's old-fashioned in all the best possible ways .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 57 / 1 / 13 / 71:  72% 72/100 [00:46<00:17,  1.56it/s]--------------------------------------------- Result 72 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (50%)\u001b[0m\n",
      "\n",
      "it's \u001b[92mdark\u001b[0m but has \u001b[92mwonderfully\u001b[0m \u001b[92mfunny\u001b[0m \u001b[92mmoments\u001b[0m ; you \u001b[92mcare\u001b[0m about the \u001b[92mcharacters\u001b[0m ; and the action and special effects are first-rate .\n",
      "\n",
      "it's \u001b[91mdismal\u001b[0m but has \u001b[91munspeakably\u001b[0m \u001b[91modd\u001b[0m \u001b[91mtiming\u001b[0m ; you \u001b[91mconsiderate\u001b[0m about the \u001b[91mcharacter\u001b[0m ; and the action and special effects are first-rate .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 58 / 1 / 13 / 72:  72% 72/100 [00:46<00:17,  1.56it/s]--------------------------------------------- Result 73 ---------------------------------------------\n",
      "\u001b[92mPositive (77%)\u001b[0m --> \u001b[91mNegative (66%)\u001b[0m\n",
      "\n",
      "in visual fertility treasure planet rivals the \u001b[92mtop\u001b[0m japanese animations of recent vintage .\n",
      "\n",
      "in visual fertility treasure planet rivals the \u001b[91muppermost\u001b[0m japanese animations of recent vintage .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 59 / 1 / 13 / 73:  74% 74/100 [00:46<00:16,  1.59it/s]--------------------------------------------- Result 74 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
      "\n",
      "enormously \u001b[92menjoyable\u001b[0m , high-adrenaline \u001b[92mdocumentary\u001b[0m .\n",
      "\n",
      "enormously \u001b[91mdroll\u001b[0m , high-adrenaline \u001b[91mpaperwork\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 60 / 1 / 13 / 74:  74% 74/100 [00:46<00:16,  1.59it/s]--------------------------------------------- Result 75 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (92%)\u001b[0m\n",
      "\n",
      "buy is an \u001b[92maccomplished\u001b[0m actress , and this is a big , \u001b[92mjuicy\u001b[0m role .\n",
      "\n",
      "buy is an \u001b[91mended\u001b[0m actress , and this is a big , \u001b[91mcrusty\u001b[0m role .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 61 / 1 / 13 / 75:  76% 76/100 [00:47<00:14,  1.61it/s]--------------------------------------------- Result 76 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
      "\n",
      "it \u001b[92mworks\u001b[0m its \u001b[92mmagic\u001b[0m with such \u001b[92mexuberance\u001b[0m and passion that the film's length becomes a part of its \u001b[92mfun\u001b[0m .\n",
      "\n",
      "it \u001b[91mfunctioned\u001b[0m its \u001b[91mconjuring\u001b[0m with such \u001b[91mfervour\u001b[0m and passion that the film's length becomes a part of its \u001b[91mbanter\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 62 / 1 / 13 / 76:  76% 76/100 [00:47<00:14,  1.61it/s]--------------------------------------------- Result 77 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (75%)\u001b[0m\n",
      "\n",
      "\u001b[92mbeautifully\u001b[0m \u001b[92mcrafted\u001b[0m and \u001b[92mbrutally\u001b[0m \u001b[92mhonest\u001b[0m , promises \u001b[92moffers\u001b[0m an unexpected \u001b[92mwindow\u001b[0m into the complexities of the middle \u001b[92meast\u001b[0m \u001b[92mstruggle\u001b[0m and into the \u001b[92mhumanity\u001b[0m of its people .\n",
      "\n",
      "\u001b[91mimpossibly\u001b[0m \u001b[91mdevising\u001b[0m and \u001b[91mhastily\u001b[0m \u001b[91mfrankly\u001b[0m , promises \u001b[91moffering\u001b[0m an unexpected \u001b[91mbeaker\u001b[0m into the complexities of the middle \u001b[91meastern\u001b[0m \u001b[91mskirmish\u001b[0m and into the \u001b[91mhumans\u001b[0m of its people .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 63 / 1 / 13 / 77:  78% 78/100 [00:48<00:13,  1.62it/s]--------------------------------------------- Result 78 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
      "\n",
      "an old-fashioned but emotionally \u001b[92mstirring\u001b[0m adventure tale of the kind they rarely make anymore .\n",
      "\n",
      "an old-fashioned but emotionally \u001b[91mtumult\u001b[0m adventure tale of the kind they rarely make anymore .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 64 / 1 / 13 / 78:  78% 78/100 [00:48<00:13,  1.62it/s]--------------------------------------------- Result 79 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (94%)\u001b[0m\n",
      "\n",
      "charlotte sometimes is a \u001b[92mgem\u001b[0m . it's always \u001b[92menthralling\u001b[0m .\n",
      "\n",
      "charlotte sometimes is a \u001b[91mbling\u001b[0m . it's always \u001b[91mhallucinatory\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 65 / 1 / 13 / 79:  80% 80/100 [00:48<00:12,  1.65it/s]--------------------------------------------- Result 80 ---------------------------------------------\n",
      "\u001b[92mPositive (87%)\u001b[0m --> \u001b[91mNegative (52%)\u001b[0m\n",
      "\n",
      "in my opinion , analyze that is not as funny or entertaining as analyze this , but it is a \u001b[92mrespectable\u001b[0m sequel .\n",
      "\n",
      "in my opinion , analyze that is not as funny or entertaining as analyze this , but it is a \u001b[91mproper\u001b[0m sequel .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 66 / 1 / 13 / 80:  80% 80/100 [00:48<00:12,  1.65it/s]--------------------------------------------- Result 81 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (93%)\u001b[0m\n",
      "\n",
      "a \u001b[92mremarkable\u001b[0m film by bernard rose .\n",
      "\n",
      "a \u001b[91mwhopping\u001b[0m film by bernard rose .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 67 / 1 / 13 / 81:  82% 82/100 [00:48<00:10,  1.68it/s]--------------------------------------------- Result 82 ---------------------------------------------\n",
      "\u001b[92mPositive (80%)\u001b[0m --> \u001b[91mNegative (80%)\u001b[0m\n",
      "\n",
      "zhuangzhuang \u001b[92mcreates\u001b[0m delicate balance of style , text , and subtext that's so simple and precise that anything discordant would topple the balance , but against all odds , nothing does .\n",
      "\n",
      "zhuangzhuang \u001b[91mcrea\u001b[0m delicate balance of style , text , and subtext that's so simple and precise that anything discordant would topple the balance , but against all odds , nothing does .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 68 / 1 / 13 / 82:  82% 82/100 [00:48<00:10,  1.68it/s]--------------------------------------------- Result 83 ---------------------------------------------\n",
      "\u001b[92mPositive (81%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
      "\n",
      "a much more \u001b[92msuccessful\u001b[0m translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .\n",
      "\n",
      "a much more \u001b[91msucceeded\u001b[0m translation than its most famous previous film adaptation , writer-director anthony friedman's similarly updated 1970 british production .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 69 / 1 / 13 / 83:  84% 84/100 [00:49<00:09,  1.71it/s]--------------------------------------------- Result 84 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
      "\n",
      "an \u001b[92moriginal\u001b[0m and \u001b[92mhighly\u001b[0m cerebral examination of the psychopathic mind\n",
      "\n",
      "an \u001b[91mrudimentary\u001b[0m and \u001b[91mexcessively\u001b[0m cerebral examination of the psychopathic mind\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 70 / 1 / 13 / 84:  84% 84/100 [00:49<00:09,  1.71it/s]--------------------------------------------- Result 85 ---------------------------------------------\n",
      "\u001b[92mPositive (94%)\u001b[0m --> \u001b[91mNegative (89%)\u001b[0m\n",
      "\n",
      "michel piccoli's \u001b[92mmoving\u001b[0m performance is this films reason for being .\n",
      "\n",
      "michel piccoli's \u001b[91mdisplaced\u001b[0m performance is this films reason for being .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 71 / 1 / 13 / 85:  86% 86/100 [00:49<00:08,  1.74it/s]--------------------------------------------- Result 86 ---------------------------------------------\n",
      "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91mNegative (90%)\u001b[0m\n",
      "\n",
      "a \u001b[92mcaptivating\u001b[0m and \u001b[92mintimate\u001b[0m \u001b[92mstudy\u001b[0m about dying and loving . . .\n",
      "\n",
      "a \u001b[91mhallucinatory\u001b[0m and \u001b[91mcosy\u001b[0m \u001b[91manalysing\u001b[0m about dying and loving . . .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 72 / 1 / 13 / 86:  86% 86/100 [00:49<00:08,  1.74it/s]--------------------------------------------- Result 87 ---------------------------------------------\n",
      "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
      "\n",
      "this is an \u001b[92melegantly\u001b[0m \u001b[92mbalanced\u001b[0m movie -- every member of the ensemble has something fascinating to do -- that doesn't reveal even a hint of artifice .\n",
      "\n",
      "this is an \u001b[91mstylishly\u001b[0m \u001b[91mbalances\u001b[0m movie -- every member of the ensemble has something fascinating to do -- that doesn't reveal even a hint of artifice .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 73 / 1 / 13 / 87:  88% 88/100 [00:49<00:06,  1.77it/s]--------------------------------------------- Result 88 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
      "\n",
      "[grant] goes beyond his usual fluttering and stammering and \u001b[92mcaptures\u001b[0m the soul of a man in pain who gradually comes to recognize it and deal with it .\n",
      "\n",
      "[grant] goes beyond his usual fluttering and stammering and \u001b[91mincarcerate\u001b[0m the soul of a man in pain who gradually comes to recognize it and deal with it .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 74 / 1 / 13 / 88:  88% 88/100 [00:49<00:06,  1.77it/s]--------------------------------------------- Result 89 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
      "\n",
      "a high-spirited buddy \u001b[92mmovie\u001b[0m about the \u001b[92mreunion\u001b[0m of \u001b[92mberlin\u001b[0m \u001b[92manarchists\u001b[0m who \u001b[92mface\u001b[0m \u001b[92marrest\u001b[0m 15 \u001b[92myears\u001b[0m after their \u001b[92mcrime\u001b[0m .\n",
      "\n",
      "a high-spirited buddy \u001b[91mstills\u001b[0m about the \u001b[91mpooling\u001b[0m of \u001b[91mhamburg\u001b[0m \u001b[91mmalcontents\u001b[0m who \u001b[91mconfrontation\u001b[0m \u001b[91mhalts\u001b[0m 15 \u001b[91manno\u001b[0m after their \u001b[91mpenal\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 75 / 1 / 13 / 89:  90% 90/100 [00:50<00:05,  1.78it/s]--------------------------------------------- Result 90 ---------------------------------------------\n",
      "\u001b[91mNegative (81%)\u001b[0m --> \u001b[38:5:240m[SKIPPED]\u001b[0m\n",
      "\n",
      "about the best thing you could say about narc is that it's a rock-solid little genre picture . whether you like it or not is basically a matter of taste .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 75 / 1 / 14 / 90:  90% 90/100 [00:50<00:05,  1.78it/s]--------------------------------------------- Result 91 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (89%)\u001b[0m\n",
      "\n",
      "an involving , \u001b[92minspirational\u001b[0m \u001b[92mdrama\u001b[0m that sometimes falls prey to its sob-story trappings .\n",
      "\n",
      "an involving , \u001b[91mincite\u001b[0m \u001b[91mcataclysmic\u001b[0m that sometimes falls prey to its sob-story trappings .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 76 / 1 / 14 / 91:  92% 92/100 [00:50<00:04,  1.81it/s]--------------------------------------------- Result 92 ---------------------------------------------\n",
      "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (78%)\u001b[0m\n",
      "\n",
      "some of the most \u001b[92minventive\u001b[0m silliness you are likely to witness in a movie theatre for some time .\n",
      "\n",
      "some of the most \u001b[91mcontrivance\u001b[0m silliness you are likely to witness in a movie theatre for some time .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 77 / 1 / 14 / 92:  92% 92/100 [00:50<00:04,  1.81it/s]--------------------------------------------- Result 93 ---------------------------------------------\n",
      "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91mNegative (72%)\u001b[0m\n",
      "\n",
      "canadian filmmaker gary burns' \u001b[92minventive\u001b[0m and mordantly \u001b[92mhumorous\u001b[0m \u001b[92mtake\u001b[0m on the soullessness of work in the \u001b[92mcity\u001b[0m .\n",
      "\n",
      "canadian filmmaker gary burns' \u001b[91mcontrivance\u001b[0m and mordantly \u001b[91mmockery\u001b[0m \u001b[91mwear\u001b[0m on the soullessness of work in the \u001b[91mlinn\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 78 / 1 / 14 / 93:  94% 94/100 [00:51<00:03,  1.82it/s]--------------------------------------------- Result 94 ---------------------------------------------\n",
      "\u001b[92mPositive (98%)\u001b[0m --> \u001b[91mNegative (82%)\u001b[0m\n",
      "\n",
      "a rollicking \u001b[92mride\u001b[0m , with jaw-dropping action sequences , striking villains , a \u001b[92mgorgeous\u001b[0m color palette , astounding technology , \u001b[92mstirring\u001b[0m music and a boffo last hour that leads up to a strangely sinister \u001b[92mhappy\u001b[0m ending .\n",
      "\n",
      "a rollicking \u001b[91mwrinkle\u001b[0m , with jaw-dropping action sequences , striking villains , a \u001b[91mleggy\u001b[0m color palette , astounding technology , \u001b[91magitation\u001b[0m music and a boffo last hour that leads up to a strangely sinister \u001b[91mhappiest\u001b[0m ending .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 79 / 1 / 14 / 94:  94% 94/100 [00:51<00:03,  1.82it/s]--------------------------------------------- Result 95 ---------------------------------------------\n",
      "\u001b[92mPositive (99%)\u001b[0m --> \u001b[91mNegative (73%)\u001b[0m\n",
      "\n",
      "everyone's insecure in lovely and \u001b[92mamazing\u001b[0m , a \u001b[92mpoignant\u001b[0m and wryly amusing film about mothers , daughters and their relationships .\n",
      "\n",
      "everyone's insecure in lovely and \u001b[91mwhopping\u001b[0m , a \u001b[91mdisquieting\u001b[0m and wryly amusing film about mothers , daughters and their relationships .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 80 / 1 / 14 / 95:  96% 96/100 [00:51<00:02,  1.85it/s]--------------------------------------------- Result 96 ---------------------------------------------\n",
      "\u001b[92mPositive (55%)\u001b[0m --> \u001b[91mNegative (72%)\u001b[0m\n",
      "\n",
      "the closest thing to the \u001b[92mexperience\u001b[0m of space travel\n",
      "\n",
      "the closest thing to the \u001b[91mpiloting\u001b[0m of space travel\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 81 / 1 / 14 / 96:  96% 96/100 [00:51<00:02,  1.85it/s]--------------------------------------------- Result 97 ---------------------------------------------\n",
      "\u001b[92mPositive (97%)\u001b[0m --> \u001b[91mNegative (96%)\u001b[0m\n",
      "\n",
      "full of \u001b[92msurprises\u001b[0m .\n",
      "\n",
      "full of \u001b[91mstumped\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 82 / 1 / 14 / 97:  98% 98/100 [00:52<00:01,  1.88it/s]--------------------------------------------- Result 98 ---------------------------------------------\n",
      "\u001b[92mPositive (90%)\u001b[0m --> \u001b[91mNegative (51%)\u001b[0m\n",
      "\n",
      "connoisseurs of chinese film will be \u001b[92mpleased\u001b[0m to discover that tian's meticulous talent has not \u001b[92mwithered\u001b[0m during his enforced hiatus .\n",
      "\n",
      "connoisseurs of chinese film will be \u001b[91mflattered\u001b[0m to discover that tian's meticulous talent has not \u001b[91mboughs\u001b[0m during his enforced hiatus .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 83 / 1 / 14 / 98:  98% 98/100 [00:52<00:01,  1.88it/s]--------------------------------------------- Result 99 ---------------------------------------------\n",
      "\u001b[92mPositive (95%)\u001b[0m --> \u001b[91mNegative (74%)\u001b[0m\n",
      "\n",
      "if you can push on through the slow spots , you'll be \u001b[92mrewarded\u001b[0m with some \u001b[92mfine\u001b[0m \u001b[92macting\u001b[0m .\n",
      "\n",
      "if you can push on through the slow spots , you'll be \u001b[91mrecompense\u001b[0m with some \u001b[91mwondrous\u001b[0m \u001b[91minterim\u001b[0m .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 84 / 1 / 14 / 99: 100% 100/100 [00:52<00:00,  1.91it/s]--------------------------------------------- Result 100 ---------------------------------------------\n",
      "\u001b[92mPositive (57%)\u001b[0m --> \u001b[91mNegative (60%)\u001b[0m\n",
      "\n",
      "an unusually dry-eyed , even analytical \u001b[92mapproach\u001b[0m to material that is generally played for maximum moisture .\n",
      "\n",
      "an unusually dry-eyed , even analytical \u001b[91mapproaches\u001b[0m to material that is generally played for maximum moisture .\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 85 / 1 / 14 / 100: 100% 100/100 [00:52<00:00,  1.91it/s]\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 85     |\n",
      "| Number of failed attacks:     | 1      |\n",
      "| Number of skipped attacks:    | 14     |\n",
      "| Original accuracy:            | 86.0%  |\n",
      "| Accuracy under attack:        | 1.0%   |\n",
      "| Attack success rate:          | 98.84% |\n",
      "| Average perturbed word %:     | 13.23% |\n",
      "| Average num. words per input: | 18.45  |\n",
      "| Avg num queries:              | 72.19  |\n",
      "+-------------------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "!textattack attack --recipe textfooler --num-examples 100 --model ./outputs/2024-09-30-08-37-16-508338/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyrJM3CaseoL"
   },
   "source": [
    "Looks like our model was 84% successful (makes sense - same evaluation set as `textattack eval`!), meaning that TextAttack attacked the model with 84 examples (since the attack won't run if an example is originally mispredicted). The attack success rate was 98.8%, meaning that TextFooler failed to find an adversarial example only 1.2% (1 out of 84) of the time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xwZqGWz8UVJ"
   },
   "source": [
    "#**TO DO: Robust models**\n",
    "\n",
    "Now that we have trained our model and saw that it was vulnerable to adversarial attacks, your next task is to improve its robustness. We can do so by training a model with adversarial data instead of the normal ones.\n",
    "\n",
    "1. To do so we need to update the training command from above to instruct textattack to use adversarial data generated with textfooler or any other attack during training.\n",
    "\n",
    "To complete the task you can take the help of the documentation of [TextAttack library ](https://textattack.readthedocs.io/en/latest/0_get_started/basic-Intro.html) and command line help option to adversarially train a model on the same dataset.\n",
    "\n",
    "***Hint***: Take a look at the [Trainer class in API](https://textattack.readthedocs.io/en/master/api/trainer.html) user guide and the [Making Vanilla Adversarial Training of NLP Models Feasible!](https://textattack.readthedocs.io/en/master/1start/A2TforVanillaAT.html)\n",
    "\n",
    "2. If the solution you found is expected to take more than 15 minutes to train, look again at the docummentation and adapt your parameters such that it will take between 5-10 minutes due to time restrictions for this class.\n",
    "\n",
    "3. Evaluate if the robustnes of the model has improved by attacking the newly trained model with TextFooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1FpXmrp5V6g",
    "outputId": "741c115d-069e-4051-cd43-be695103c6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: [python -m] texattack <command> [<args>] train [-h]\n",
      "                                                      --model-name-or-path\n",
      "                                                      MODEL_NAME_OR_PATH\n",
      "                                                      [--model-max-length MODEL_MAX_LENGTH]\n",
      "                                                      [--model-num-labels MODEL_NUM_LABELS]\n",
      "                                                      [--attack ATTACK]\n",
      "                                                      [--task-type TASK_TYPE]\n",
      "                                                      --dataset DATASET\n",
      "                                                      [--dataset-train-split DATASET_TRAIN_SPLIT]\n",
      "                                                      [--dataset-eval-split DATASET_EVAL_SPLIT]\n",
      "                                                      [--filter-train-by-labels FILTER_TRAIN_BY_LABELS [FILTER_TRAIN_BY_LABELS ...]]\n",
      "                                                      [--filter-eval-by-labels FILTER_EVAL_BY_LABELS [FILTER_EVAL_BY_LABELS ...]]\n",
      "                                                      [--num-epochs NUM_EPOCHS]\n",
      "                                                      [--num-clean-epochs NUM_CLEAN_EPOCHS]\n",
      "                                                      [--attack-epoch-interval ATTACK_EPOCH_INTERVAL]\n",
      "                                                      [--early-stopping-epochs EARLY_STOPPING_EPOCHS]\n",
      "                                                      [--learning-rate LEARNING_RATE]\n",
      "                                                      [--num-warmup-steps NUM_WARMUP_STEPS]\n",
      "                                                      [--weight-decay WEIGHT_DECAY]\n",
      "                                                      [--per-device-train-batch-size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
      "                                                      [--per-device-eval-batch-size PER_DEVICE_EVAL_BATCH_SIZE]\n",
      "                                                      [--gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                                      [--random-seed RANDOM_SEED]\n",
      "                                                      [--parallel]\n",
      "                                                      [--load-best-model-at-end]\n",
      "                                                      [--alpha ALPHA]\n",
      "                                                      [--num-train-adv-examples NUM_TRAIN_ADV_EXAMPLES]\n",
      "                                                      [--query-budget-train QUERY_BUDGET_TRAIN]\n",
      "                                                      [--attack-num-workers-per-device ATTACK_NUM_WORKERS_PER_DEVICE]\n",
      "                                                      [--output-dir OUTPUT_DIR]\n",
      "                                                      [--checkpoint-interval-steps CHECKPOINT_INTERVAL_STEPS]\n",
      "                                                      [--checkpoint-interval-epochs CHECKPOINT_INTERVAL_EPOCHS]\n",
      "                                                      [--save-last]\n",
      "                                                      [--log-to-tb]\n",
      "                                                      [--tb-log-dir TB_LOG_DIR]\n",
      "                                                      [--log-to-wandb]\n",
      "                                                      [--wandb-project WANDB_PROJECT]\n",
      "                                                      [--logging-interval-step LOGGING_INTERVAL_STEP]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --model-name-or-path MODEL_NAME_OR_PATH, --model MODEL_NAME_OR_PATH\n",
      "                        Name or path of the model we want to create. \"lstm\"\n",
      "                        and \"cnn\" will create TextAttack's LSTM and CNN models\n",
      "                        while any other input will be used to create\n",
      "                        Transformers model. (e.g.\"brt-base-uncased\").\n",
      "                        (default: None)\n",
      "  --model-max-length MODEL_MAX_LENGTH\n",
      "                        The maximum sequence length of the model. (default:\n",
      "                        None)\n",
      "  --model-num-labels MODEL_NUM_LABELS\n",
      "                        The number of labels for classification. (default:\n",
      "                        None)\n",
      "  --attack ATTACK       Attack recipe to use (enables adversarial training)\n",
      "                        (default: None)\n",
      "  --task-type TASK_TYPE\n",
      "                        Type of task model is supposed to perform. Options:\n",
      "                        `classification`, `regression`. (default:\n",
      "                        classification)\n",
      "  --dataset DATASET     dataset for training; will be loaded from `datasets`\n",
      "                        library. if dataset has a subset, separate with a\n",
      "                        colon. ex: `glue^sst2` or `rotten_tomatoes` (default:\n",
      "                        yelp)\n",
      "  --dataset-train-split DATASET_TRAIN_SPLIT\n",
      "                        train dataset split, if non-standard (can\n",
      "                        automatically detect 'train' (default: )\n",
      "  --dataset-eval-split DATASET_EVAL_SPLIT\n",
      "                        val dataset split, if non-standard (can automatically\n",
      "                        detect 'dev', 'validation', 'eval') (default: )\n",
      "  --filter-train-by-labels FILTER_TRAIN_BY_LABELS [FILTER_TRAIN_BY_LABELS ...]\n",
      "                        List of labels to keep in the train dataset and\n",
      "                        discard all others. (default: None)\n",
      "  --filter-eval-by-labels FILTER_EVAL_BY_LABELS [FILTER_EVAL_BY_LABELS ...]\n",
      "                        List of labels to keep in the eval dataset and discard\n",
      "                        all others. (default: None)\n",
      "  --num-epochs NUM_EPOCHS, --epochs NUM_EPOCHS\n",
      "                        Total number of epochs for training. (default: 3)\n",
      "  --num-clean-epochs NUM_CLEAN_EPOCHS\n",
      "                        Number of epochs to train on the clean dataset before\n",
      "                        adversarial training (N/A if --attack unspecified)\n",
      "                        (default: 1)\n",
      "  --attack-epoch-interval ATTACK_EPOCH_INTERVAL\n",
      "                        Generate a new adversarial training set every N\n",
      "                        epochs. (default: 1)\n",
      "  --early-stopping-epochs EARLY_STOPPING_EPOCHS\n",
      "                        Number of epochs validation must increase before\n",
      "                        stopping early (-1 for no early stopping) (default:\n",
      "                        None)\n",
      "  --learning-rate LEARNING_RATE, --lr LEARNING_RATE\n",
      "                        Learning rate for Adam Optimization. (default: 5e-05)\n",
      "  --num-warmup-steps NUM_WARMUP_STEPS\n",
      "                        The number of steps for the warmup phase of linear\n",
      "                        scheduler. (default: 500)\n",
      "  --weight-decay WEIGHT_DECAY\n",
      "                        Weight decay (L2 penalty). (default: 0.01)\n",
      "  --per-device-train-batch-size PER_DEVICE_TRAIN_BATCH_SIZE\n",
      "                        The batch size per GPU/CPU for training. (default: 8)\n",
      "  --per-device-eval-batch-size PER_DEVICE_EVAL_BATCH_SIZE\n",
      "                        The batch size per GPU/CPU for evaluation. (default:\n",
      "                        32)\n",
      "  --gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS\n",
      "                        Number of updates steps to accumulate the gradients\n",
      "                        for, before performing a backward/update pass.\n",
      "                        (default: 1)\n",
      "  --random-seed RANDOM_SEED\n",
      "                        Random seed. (default: 786)\n",
      "  --parallel            If set, run training on multiple GPUs. (default:\n",
      "                        False)\n",
      "  --load-best-model-at-end\n",
      "                        If set, keep track of the best model across training\n",
      "                        and load it at the end. (default: False)\n",
      "  --alpha ALPHA         The weight of adversarial loss. (default: 1.0)\n",
      "  --num-train-adv-examples NUM_TRAIN_ADV_EXAMPLES\n",
      "                        The number of samples to attack when generating\n",
      "                        adversarial training set. Default is -1 (which is all\n",
      "                        possible samples). (default: -1)\n",
      "  --query-budget-train QUERY_BUDGET_TRAIN\n",
      "                        The max query budget to use when generating\n",
      "                        adversarial training set. (default: None)\n",
      "  --attack-num-workers-per-device ATTACK_NUM_WORKERS_PER_DEVICE\n",
      "                        Number of worker processes to run per device for\n",
      "                        attack. Same as `num_workers_per_device` argument for\n",
      "                        `AttackArgs`. (default: 1)\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        Directory to output training logs and checkpoints.\n",
      "                        (default: ./outputs/2022-11-24-15-44-45-406385)\n",
      "  --checkpoint-interval-steps CHECKPOINT_INTERVAL_STEPS\n",
      "                        Save model checkpoint after every N updates to the\n",
      "                        model. (default: None)\n",
      "  --checkpoint-interval-epochs CHECKPOINT_INTERVAL_EPOCHS\n",
      "                        Save model checkpoint after every N epochs. (default:\n",
      "                        None)\n",
      "  --save-last           If set, save the model at end of training. Can be used\n",
      "                        with `--load-best-model-at-end` to save the best model\n",
      "                        at the end. (default: True)\n",
      "  --log-to-tb           If set, log to Tensorboard (default: False)\n",
      "  --tb-log-dir TB_LOG_DIR\n",
      "                        Path of Tensorboard log directory. (default: None)\n",
      "  --log-to-wandb        If set, log to Wandb. (default: False)\n",
      "  --wandb-project WANDB_PROJECT\n",
      "                        Name of Wandb project for logging. (default:\n",
      "                        textattack)\n",
      "  --logging-interval-step LOGGING_INTERVAL_STEP\n",
      "                        Log to Tensorboard/Wandb every N steps. (default: 1)\n"
     ]
    }
   ],
   "source": [
    "!textattack train --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QQZ_cWlUMOz",
    "outputId": "1adc1816-83db-4dd2-cfed-8117ceb2d87a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: textattack: command not found\n"
     ]
    }
   ],
   "source": [
    "  ### Modify the  following command to perform adversarial training\n",
    "\n",
    "  !textattack train --attack textfooler --model-name-or-path distilbert-base-uncased --dataset rotten_tomatoes --model-num-labels 2 --model-max-length 64 --per-device-train-batch-size 128 --num-epochs 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qk-hZgLVxJ00"
   },
   "outputs": [],
   "source": [
    "!textattack eval --num-examples 1000 --model ./outputs/2024-09-30-08-37-16-508338/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!textattack attack --recipe textfooler --num-examples 100 --model ./outputs/2024-09-30-08-37-16-508338/best_model/ --dataset-from-huggingface rotten_tomatoes --dataset-split test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
