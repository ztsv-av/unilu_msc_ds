# Introduction

## Problem

1. Deep learning **models** usually **need a lot of training and labelled data**.
2. Labelled **data** is **scarce** and **expensive**. Data scarcity limits the performance and applicability of deep learning models.
3. Show examples of domains where labeled data is scarce.

## Data Augmentation

1. **To deal with** this problem people use **data augmentation**.
2. Define what data augmentation entails: Data augmentation is a way to increase the size of training datasets.
   1. Show simple examples of data augmentation in images (e.g., rotations, flips).
3. Data augmentation improves the generalization capabilities of models for different machine learning tasks.
4. Data augmentation saves time and resources.

## Problem with Data Augmentation Techniques

1. Existing data augmentation methods are manually designed and evaluated for different modalities separately.
2. Modalities are different forms or types of data such as images, text, or audio
   1. For example imaging processing functions for image data (e.g. rotations) (include figure: image -> augmented image)
   2. Word-replacing rules for text data (e.g. synonym replacement) (include figure: text -> augmented text).

## Solution: MODALS

1. MODALS: Modality-agnostic Automated Data Augmentation in the Latent Space. 
    1. **Modality-agnostic** refers to being **independent of any type of form of data** being processed (modality=data, agnostic=independent). 
    2. **Automated** means you do not need to manually define data augmentation functions, MODALS **searches for the optimal augmentation strategies** by itself.
    3. **Latent space** is a lower-dimensional intermediate representation of input data learned by the machine learning model.
    4. Show figure: image, text, time-series -> latent vector -> augmentation function.
2. MODALS transforms data in the latent space, while previous data augmentation methods have transformed data in the input space.
3. **MODALS** is a **general automated data augmentation framework** that can work for any data modality (since we transform data in the latent space).

## Results: Teaser

1. MODALS was tested on text, tabular, time-series, and image datasets.
2. It outperformed baseline methods in most cases (baseline=standard data augmentation techniques specific to modality).
3. Perhaps show a high-level graph or chart summarizing the performance improvements.
4. **For data modalities where input space augmentation is difficult to define, MODALS might be the best solution yet**.

# Guts of MODALS

## Algorithm

1. Show simple ML process: Input data -> NN -> Classification Head -> Output.
2. Show with augmentation: Input data -> Augmentation -> NN -> Classification Head -> Output.
3. Now show MODALS: Figure 2.
4. Show step by step Algorithm:
   1. Data ($X$): The input dataset consisting of samples from any modality (e.g., images, text, audio, tabular data).
   2. Feature Extractor: A neural network that transforms the input data $X$ into latent representations $Z$.
   3. Triplet loss: Triplet loss is used to learn the latent representations of different classes. Triplet loss encourages the model to make latent representations of the same class closer together and those of different classes further apart. **Used to**: the new augmented representations stay within the correct class and maintain label consistency.
   4. Discriminator: A neural network trained in a way that tries to fool another part of the network to ensure that the latent representations $Z$ follow a desired distribution, Gaussian, promoting smoothness and validity in the augmented latent space. Distriminator is used to distringuish the latent code generated by the Feature Extractor and a sample from the Gaussian distribution. The Feature Extractor then has to generate latent representations that are similar to the Gaussian distribution to fool the distriminator. **Used to**: when we modify the latent representations, the changes are smooth and produce realistic variations between data points.
   5. Augmentation Policy PBA: Population-Based Augmentation (PBA) is **used to** automatically search for and optimize the augmentation policiesâ€”that is, it determines **which transformations to apply, their probabilities, and magnitudes** and applies them to the latent representations. In the paper, they define 4 label-preserving transformations, and PBA learns their parameters, how to combine these transformations apply the combination to the latent vector $z_i$.
   6. Dense Layer: A final neural network layer that maps the (possibly augmented) latent representations $\hat{Z}$ to predicted labels $\hat{Y}$ performing the classification task.

## Example

A single, simple image classification task to walk through each step. Include visuals at each step.
1. Some image -> 
2. Feature Extractor -> 
3. Figure 1 b (e.g.) -> 
4. Triplet loss formula -> $L_{tri}(\theta, z)=d(z, z^+)-d(z, z^-)+\gamma$, where $z^+$ sampled latent representation from the same class, $z^-$ sampled latent representation from different class, $\gamma$ a margin, prevents the embeddings of different classes from overlapping in the latent space, encourages the model to make embeddings of the same class more tightly clustered and embeddings of different classes more widely separated. As a result of using the triplet loss, the distribution of the latent representations in the same class will be more compact. Interpolating, extrapolating or perturbing latent representations in this denser region is more likely to result in an augmented example sharing the same class identity.
5. Discriminator -> 
6. Policy -> 
7. Classification head -> 
8. Output.

# Results

## MODALS Perfomance

1. Perfomance comparison between MODALS and baseline models (perhaps don't use tables, since they might be too dense).
   1. Explain the metrics used.
   2. Text data.
   3. Tabular data.
   4. Time-series data.
   5. Image data.
   6. Losses ("You might wonder, why use so many losses, discriminator, triplet loss?")

## Insights

1. Overall, MODALS was successful and achieved good results.
2. MODALS was able to improve the performance of deep learning models in many cases (except image).
   1. MODALS was particularly successful for tabular data.
   2. Why not image? 
      1. "Input space augmentations used in PBA are able to cover most variations in these datasets due to continious nature of the image data". 
      2. Future work: it's possible to combine PBA with MODALS to further improve the results.

## How MODALS can Impact the ML World?

- MODALS provides a general framework for data augmentation that can be applied to different data modalities.
- Mention industries or applications that could particularly benefit from MODALS (e.g., medical imaging, natural language processing in low-resource languages).
- This could save researchers time and resources.
- MODALS could make it easier to develop deep learning models for new data modalities.

# Conclusions

1. MODALS is a new **automatic** **data augmentation** technique that transforms data in the latent space, increasing the size of the training data.
2. MODALS can be used for any data type.
3. MODALS proposes a novel way to create hard examples, which makes models more robust.
4. They test the algorithm on text, tabular, time-series and image data and achieve best results except for image modality.
5. MODALS can be easily intergrated into any DL pipeline.
6. One of the greatest advantages of MODALS is its applicability to data modalities where input space augmentation is difficult to define, such as text data, video data, or even graph data.
